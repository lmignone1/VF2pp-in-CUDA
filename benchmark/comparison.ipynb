{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26646,"status":"ok","timestamp":1722762914214,"user":{"displayName":"Sabrina Olivari","userId":"03563423152767973544"},"user_tz":-120},"id":"LXrkepY6j6WY","outputId":"03d49049-dc82-4961-8283-9efebb0e0284"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]},{"data":{"text/plain":["['README.md',\n"," 'LICENSE',\n"," '.tips',\n"," '.imp',\n"," 'temp_ordering.cu',\n"," '.gitignore',\n"," 'Makefile',\n"," 'tmp',\n"," 'src',\n"," 'data',\n"," '.git',\n"," 'benchmark']"]},"execution_count":1,"metadata":{},"output_type":"execute_result"}],"source":["from google.colab import drive\n","import os\n","\n","drive.mount('/content/drive')\n","os.chdir(\"drive/MyDrive/VF2pp-in-CUDA/\")\n","os.listdir()"]},{"cell_type":"markdown","metadata":{"id":"LwMqALr4j6WZ"},"source":["CUDA SETUP"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":155672,"status":"ok","timestamp":1722763069879,"user":{"displayName":"Sabrina Olivari","userId":"03563423152767973544"},"user_tz":-120},"id":"XZ8F6AJWj6Wb","outputId":"b8c05b05-4645-4e56-ac09-03dda1460b58"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting nvcc4jupyter\n","  Downloading nvcc4jupyter-1.2.1-py3-none-any.whl.metadata (5.1 kB)\n","Downloading nvcc4jupyter-1.2.1-py3-none-any.whl (10 kB)\n","Installing collected packages: nvcc4jupyter\n","Successfully installed nvcc4jupyter-1.2.1\n","Collecting pycuda\n","  Downloading pycuda-2024.1.2.tar.gz (1.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m45.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Collecting pytools>=2011.2 (from pycuda)\n","  Downloading pytools-2024.1.11-py3-none-any.whl.metadata (3.0 kB)\n","Requirement already satisfied: platformdirs>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from pycuda) (4.2.2)\n","Collecting mako (from pycuda)\n","  Downloading Mako-1.3.5-py3-none-any.whl.metadata (2.9 kB)\n","Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from pytools>=2011.2->pycuda) (4.12.2)\n","Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from mako->pycuda) (2.1.5)\n","Downloading pytools-2024.1.11-py3-none-any.whl (88 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.2/88.2 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading Mako-1.3.5-py3-none-any.whl (78 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: pycuda\n","  Building wheel for pycuda (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pycuda: filename=pycuda-2024.1.2-cp310-cp310-linux_x86_64.whl size=662246 sha256=6d165b1b0e17a03c75d1efd7f11fa341d44e6ed4c27107b4b3e7600886dc7e6a\n","  Stored in directory: /root/.cache/pip/wheels/70/63/40/4bf006182f942d3516b71bb2ff3b57ccbdb8b2c0ee81882b6e\n","Successfully built pycuda\n","Installing collected packages: pytools, mako, pycuda\n","Successfully installed mako-1.3.5 pycuda-2024.1.2 pytools-2024.1.11\n"]}],"source":["!pip install nvcc4jupyter\n","!pip install pycuda"]},{"cell_type":"markdown","metadata":{"id":"qBLCrwbmj6Wb"},"source":["GPU TYPE"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1722763069879,"user":{"displayName":"Sabrina Olivari","userId":"03563423152767973544"},"user_tz":-120},"id":"xYkG4idRj6Wb","outputId":"6e955db1-0ee7-4326-e71c-778ca4c08c75"},"outputs":[{"name":"stdout","output_type":"stream","text":["Sun Aug  4 09:17:49 2024       \n","+---------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n","|-----------------------------------------+----------------------+----------------------+\n","| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                      |               MIG M. |\n","|=========================================+======================+======================|\n","|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n","| N/A   52C    P8               9W /  70W |      0MiB / 15360MiB |      0%      Default |\n","|                                         |                      |                  N/A |\n","+-----------------------------------------+----------------------+----------------------+\n","                                                                                         \n","+---------------------------------------------------------------------------------------+\n","| Processes:                                                                            |\n","|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n","|        ID   ID                                                             Usage      |\n","|=======================================================================================|\n","|  No running processes found                                                           |\n","+---------------------------------------------------------------------------------------+\n","nvcc: NVIDIA (R) Cuda compiler driver\n","Copyright (c) 2005-2023 NVIDIA Corporation\n","Built on Tue_Aug_15_22:02:13_PDT_2023\n","Cuda compilation tools, release 12.2, V12.2.140\n","Build cuda_12.2.r12.2/compiler.33191640_0\n","Detected platform \"Colab\". Running its setup...\n","Source files will be saved in \"/tmp/tmp45jwiduz\".\n"]}],"source":["!nvidia-smi\n","!nvcc --version\n","%load_ext nvcc4jupyter"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":515,"status":"ok","timestamp":1722711146129,"user":{"displayName":"Sabrina Olivari","userId":"03563423152767973544"},"user_tz":-120},"id":"HIJp4aitj6Wc","outputId":"11f4bba2-abfa-4da4-f0d1-9234ca2460ee"},"outputs":[{"name":"stdout","output_type":"stream","text":["1 device(s) found.\n","Device #0: Tesla T4\n"," Compute Capability: 7.5\n"," Total Memory: 14 GB\n"]}],"source":["import pycuda.driver as drv\n","import pycuda.autoinit\n","drv.init()\n","print(\"%d device(s) found.\" % drv.Device.count())\n","for i in range(drv.Device.count()):\n","  dev = drv.Device(i)\n","  print(\"Device #%d: %s\" % (i, dev.name()))\n","  print(\" Compute Capability: %d.%d\" % dev.compute_capability())\n","  print(\" Total Memory: %s GB\" % (dev.total_memory() // (1024 * 1024 * 1024)))"]},{"cell_type":"markdown","metadata":{"id":"1YG2FJsIj6Wc"},"source":["GPU INFO"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1531,"status":"ok","timestamp":1722711147657,"user":{"displayName":"Sabrina Olivari","userId":"03563423152767973544"},"user_tz":-120},"id":"M3NtaKiNj6Wc","outputId":"f88d02ed-1354-4c10-f8f0-99ff1dfd8b08"},"outputs":[{"name":"stdout","output_type":"stream","text":["Device number: 0\n","  Device name: Tesla T4\n","  Compute capability: 7.5\n","\n","  Clock Rate: 1590000 kHz\n","  Total SMs: 40 \n","  Shared Memory Per SM: 65536 bytes\n","  Registers Per SM: 65536 32-bit\n","  Max threads per SM: 1024\n","  L2 Cache Size: 4194304 bytes\n","  Total Global Memory: 15835660288 bytes\n","  Memory Clock Rate: 5001000 kHz\n","\n","  Max threads per block: 1024\n","  Max threads in X-dimension of block: 1024\n","  Max threads in Y-dimension of block: 1024\n","  Max threads in Z-dimension of block: 64\n","\n","  Max blocks in X-dimension of grid: 2147483647\n","  Max blocks in Y-dimension of grid: 65535\n","  Max blocks in Z-dimension of grid: 65535\n","\n","  Warp size: 32\n","\n"," Constant Memory: 65536\n"," Max resident blocks per SM: 16\n","\n"]}],"source":["%%cuda\n","\n","#include <stdio.h>\n","#include <stdlib.h>\n","\n","void deviceQuery()\n","{\n","  cudaDeviceProp prop;\n","  int nDevices=0, i;\n","  cudaError_t ierr;\n","\n","  ierr = cudaGetDeviceCount(&nDevices);\n","  if (ierr != cudaSuccess) { printf(\"Sync error: %s\\n\", cudaGetErrorString(ierr)); }\n","\n","\n","\n","  for( i = 0; i < nDevices; ++i )\n","  {\n","     ierr = cudaGetDeviceProperties(&prop, i);\n","     printf(\"Device number: %d\\n\", i);\n","     printf(\"  Device name: %s\\n\", prop.name);\n","     printf(\"  Compute capability: %d.%d\\n\\n\", prop.major, prop.minor);\n","\n","     printf(\"  Clock Rate: %d kHz\\n\", prop.clockRate);\n","     printf(\"  Total SMs: %d \\n\", prop.multiProcessorCount);\n","     printf(\"  Shared Memory Per SM: %lu bytes\\n\", prop.sharedMemPerMultiprocessor);\n","     printf(\"  Registers Per SM: %d 32-bit\\n\", prop.regsPerMultiprocessor);\n","     printf(\"  Max threads per SM: %d\\n\", prop.maxThreadsPerMultiProcessor);\n","     printf(\"  L2 Cache Size: %d bytes\\n\", prop.l2CacheSize);\n","     printf(\"  Total Global Memory: %lu bytes\\n\", prop.totalGlobalMem);\n","     printf(\"  Memory Clock Rate: %d kHz\\n\\n\", prop.memoryClockRate);\n","\n","\n","     printf(\"  Max threads per block: %d\\n\", prop.maxThreadsPerBlock);\n","     printf(\"  Max threads in X-dimension of block: %d\\n\", prop.maxThreadsDim[0]);\n","     printf(\"  Max threads in Y-dimension of block: %d\\n\", prop.maxThreadsDim[1]);\n","     printf(\"  Max threads in Z-dimension of block: %d\\n\\n\", prop.maxThreadsDim[2]);\n","\n","     printf(\"  Max blocks in X-dimension of grid: %d\\n\", prop.maxGridSize[0]);\n","     printf(\"  Max blocks in Y-dimension of grid: %d\\n\", prop.maxGridSize[1]);\n","     printf(\"  Max blocks in Z-dimension of grid: %d\\n\\n\", prop.maxGridSize[2]);\n","\n","     printf(\"  Warp size: %d\\n\\n\", prop.warpSize);\n","     printf(\" Constant Memory: %d\\n\", prop.totalConstMem);\n","     printf(\" Max resident blocks per SM: %d\\n\", prop.maxBlocksPerMultiProcessor);\n","  }\n","}\n","\n","int main() {\n","    deviceQuery();\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ui8H7vkPj6Wd"},"outputs":[],"source":["!make clean\n","!make"]},{"cell_type":"markdown","metadata":{"id":"OOnE1-39qxtB"},"source":["CHOOSE THE BEST BLOCKSIZE ON RANDOM GRAPH OF DIFFERENT SIZES"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zTi0sph_qxtB"},"outputs":[],"source":["import os\n","\n","graph_dimension = [3000, 5000, 8000, 10000]\n","blocksize = [64, 128, 256, 512]\n","\n","for bs in blocksize:\n","    for dim in graph_dimension:\n","        cmd_parallel = f\"./vf2pp_parallel_O0 {dim} 3 {bs}\"\n","        !{cmd_parallel}\n"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":458,"status":"ok","timestamp":1722764577888,"user":{"displayName":"Sabrina Olivari","userId":"03563423152767973544"},"user_tz":-120},"id":"wzHX0U2FrCM4","outputId":"56f5c864-70da-49e1-ab84-c9e85c0f170b"},"outputs":[{"name":"stdout","output_type":"stream","text":["                BLOCKSIZE 64  BLOCKSIZE 128  BLOCKSIZE 256  BLOCKSIZE 512\n","Execution Time     20.718315      20.294913      20.048738      21.525348\n"]}],"source":["'''\n","Each file name is of the type \"result_{dim}_3.txt\" so each file will contain 4 values, one for each blocksize used.\n","So each file represents the execution times on the graph of size \"dim\" with different blocksizes.\n","We begin by running the simulation, and then, for each blocksize, we calculate the average execution time across all dimensions of the graph.\n","The best one is 256 because it's the minimum average execution time across all dimensions. In addition, it has an occupancy of 25 percent. \n","'''\n","\n","!mkdir -p ./benchmark/measures/blocksize\n","!mv ./benchmark/measures/parallel/* ./benchmark/measures/blocksize/\n","\n","import os\n","\n","def read_files(directory):\n","    measures = {0: [], 1: [], 2: [], 3: []}\n","\n","    files = os.listdir(directory)\n","\n","    for file in files:\n","        with open(os.path.join(directory, file), 'r') as f:\n","            line = f.read()\n","            times = line.split()\n","            for i, time in enumerate(times):\n","                measures[i].append(float(time))\n","\n","    return measures\n","\n","def calculate_means(measures):\n","    means = []\n","\n","    for key, values in measures.items():\n","        mean = sum(values) / len(values)\n","        means.append(mean)\n","\n","    return means\n","\n","measures = read_files(\"./benchmark/measures/blocksize/\")\n","\n","means = calculate_means(measures)\n","\n","import pandas as pd\n","\n","data = {\n","    f\"BLOCKSIZE {blocksize[0]}\": [means[0]],\n","    f\"BLOCKSIZE {blocksize[1]}\": [means[1]],\n","    f\"BLOCKSIZE {blocksize[2]}\": [means[2]],\n","    f\"BLOCKSIZE {blocksize[3]}\": [means[3]],\n","}\n","\n","df = pd.DataFrame(data, index=[\"Execution Time\"])\n","\n","output_directory = \"./benchmark/measures/blocksize\"\n","output_file = os.path.join(output_directory, \"blocksize_means_results.csv\")\n","df.to_csv(output_file)\n","\n","print(df)"]},{"cell_type":"markdown","metadata":{"id":"IUWPiq-Tj6Wd"},"source":["CHOOSE THE BEST OPTIMIZATION ON RANDOM GRAPH OF DIFFERENT SIZES"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wBXFt35Zj6Wd"},"outputs":[],"source":["graph_dimension = [3000, 5000, 8000, 10000]\n","optimizations = ['O0','O1','O2','O3']\n","\n","for opt in optimizations:\n","    for dim in graph_dimension:\n","        cmd_sequential = f\"./vf2pp_sequential_{opt} {dim} 3\"\n","        cmd_parallel = f\"./vf2pp_parallel_{opt} {dim} 3 256\"\n","        !{cmd_sequential}\n","        !{cmd_parallel}"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":400,"status":"ok","timestamp":1722714773508,"user":{"displayName":"Sabrina Olivari","userId":"03563423152767973544"},"user_tz":-120},"id":"siLWAXyFj6We","outputId":"0ca2f450-ebc8-4490-e018-1886556127d1"},"outputs":[{"name":"stdout","output_type":"stream","text":["                  OPTIMIZATION 0  OPTIMIZATION 1  OPTIMIZATION 2  \\\n","Sequential Means     1046.065460      551.812976      567.564568   \n","Parallel Means         19.479678       19.111196       19.600804   \n","\n","                  OPTIMIZATION 3  \n","Sequential Means      678.450359  \n","Parallel Means         19.885869  \n"]}],"source":["'''\n","Each file name is of the type \"result_{dim}_3.txt\" so each file will contain 4 values, one for each optimization performed.\n","So each file represents the execution times on the graph of size \"dim\" with different optimizations.\n","We begin by running the simulation, and then, for each optimization, we calculate the average execution time across all dimensions of the graph.\n","The best optimization is the O1 for both sequential and parallel versions with the optimal blocksize that's 256.\n","'''\n","\n","!mkdir -p ./benchmark/measures/optimizations/sequential\n","!mkdir -p ./benchmark/measures/optimizations/parallel\n","!mv ./benchmark/measures/sequential/* ./benchmark/measures/optimizations/sequential/\n","!mv ./benchmark/measures/parallel/* ./benchmark/measures/optimizations/parallel/\n","\n","import os\n","\n","def read_files(directory):\n","    measures = {0: [], 1: [], 2: [], 3: []}\n","\n","    files = os.listdir(directory)\n","\n","    for file in files:\n","        with open(os.path.join(directory, file), 'r') as f:\n","            line = f.read()\n","            times = line.split()\n","            for i, time in enumerate(times):\n","                measures[i].append(float(time))\n","\n","    return measures\n","\n","def calculate_means(measures):\n","    means = []\n","\n","    for key, values in measures.items():\n","        mean = sum(values) / len(values)\n","        means.append(mean)\n","\n","    return means\n","\n","seq_measures = read_files(\"./benchmark/measures/optimizations/sequential/\")\n","par_measures = read_files(\"./benchmark/measures/optimizations/parallel/\")\n","\n","seq_means = calculate_means(seq_measures)\n","par_means = calculate_means(par_measures)\n","\n","import pandas as pd\n","\n","data = {\n","    \"OPTIMIZATION 0\": [seq_means[0], par_means[0]],\n","    \"OPTIMIZATION 1\": [seq_means[1], par_means[1]],\n","    \"OPTIMIZATION 2\": [seq_means[2], par_means[2]],\n","    \"OPTIMIZATION 3\": [seq_means[3], par_means[3]],\n","}\n","\n","df = pd.DataFrame(data, index=[\"Sequential Means\", \"Parallel Means\"])\n","\n","output_directory = \"./benchmark/measures/optimizations\"\n","output_file = os.path.join(output_directory, \"opt_means_results.csv\")\n","df.to_csv(output_file)\n","\n","print(df)\n"]},{"cell_type":"markdown","metadata":{},"source":["SPEED UP ANALYSIS"]},{"cell_type":"markdown","metadata":{},"source":["SIMULATIONS ON SPARSE GRAPH OF DIFFERENT SIZES"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["graph_dimension = [3000, 5000, 8000, 10000]\n","\n","for dim in graph_dimension:\n","    cmd_sequential = f\"./vf2pp_sequential_O1 {dim} 0\"\n","    !{cmd_sequential}\n","\n","!mkdir -p ./benchmark/measures/simulations_graphs/sparse/sequential\n","!mv ./benchmark/measures/sequential/* ./benchmark/measures/simulations_graphs/sparse/sequential/"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["graph_dimension = [3000, 5000, 8000, 10000]\n","\n","for dim in graph_dimension:\n","    cmd_parallel = f\"./vf2pp_parallel_O1 {dim} 0 256\"\n","    !{cmd_parallel}\n","\n","!mkdir -p ./benchmark/measures/simulations_graphs/sparse/parallel\n","!mv ./benchmark/measures/parallel/* ./benchmark/measures/simulations_graphs/sparse/parallel/"]},{"cell_type":"markdown","metadata":{},"source":["SIMULATIONS ON DENSE GRAPH OF DIFFERENT SIZES"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["graph_dimension = [3000, 5000, 8000, 10000]\n","\n","for dim in graph_dimension:\n","    cmd_sequential = f\"./vf2pp_sequential_O1 {dim} 1\"\n","    !{cmd_sequential}\n","\n","!mkdir -p ./benchmark/measures/simulations_graphs/dense/sequential\n","!mv ./benchmark/measures/sequential/* ./benchmark/measures/simulations_graphs/dense/sequential/"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["graph_dimension = [3000, 5000, 8000, 10000]\n","\n","for dim in graph_dimension:\n","    cmd_parallel = f\"./vf2pp_parallel_O1 {dim} 1 256\"\n","    !{cmd_parallel}\n","\n","!mkdir -p ./benchmark/measures/simulations_graphs/dense/parallel\n","!mv ./benchmark/measures/parallel/* ./benchmark/measures/simulations_graphs/dense/parallel/"]},{"cell_type":"markdown","metadata":{},"source":["SIMULATIONS ON COMPLETE GRAPH OF DIFFERENT SIZES"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["graph_dimension = [3000, 5000, 8000]\n","\n","for dim in graph_dimension:\n","    cmd_sequential = f\"./vf2pp_sequential_O1 {dim} 2\"\n","    !{cmd_sequential}\n","\n","!mkdir -p ./benchmark/measures/simulations_graphs/complete/sequential\n","!mv ./benchmark/measures/sequential/* ./benchmark/measures/simulations_graphs/complete/sequential/"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["graph_dimension = [3000, 5000, 8000]\n","\n","for dim in graph_dimension:\n","    cmd_parallel = f\"./vf2pp_parallel_O1 {dim} 2 256\"\n","    !{cmd_parallel}\n","\n","!mkdir -p ./benchmark/measures/simulations_graphs/complete/parallel\n","!mv ./benchmark/measures/parallel/* ./benchmark/measures/simulations_graphs/complete/parallel/"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
