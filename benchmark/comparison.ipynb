{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18562,"status":"ok","timestamp":1722710997497,"user":{"displayName":"Sabrina Olivari","userId":"03563423152767973544"},"user_tz":-120},"id":"LXrkepY6j6WY","outputId":"8889f127-3569-4084-af38-0497d762adb8"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]},{"data":{"text/plain":["['README.md',\n"," 'LICENSE',\n"," '.tips',\n"," '.imp',\n"," 'temp_ordering.cu',\n"," '.gitignore',\n"," 'Makefile',\n"," 'test.py',\n"," 'src',\n"," 'data',\n"," 'benchmark',\n"," '.git',\n"," 'tmp']"]},"execution_count":1,"metadata":{},"output_type":"execute_result"}],"source":["from google.colab import drive\n","import os\n","\n","drive.mount('/content/drive')\n","os.chdir(\"drive/MyDrive/VF2pp-in-CUDA/\")\n","os.listdir()"]},{"cell_type":"markdown","metadata":{"id":"LwMqALr4j6WZ"},"source":["CUDA SETUP"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":148127,"status":"ok","timestamp":1722711145620,"user":{"displayName":"Sabrina Olivari","userId":"03563423152767973544"},"user_tz":-120},"id":"XZ8F6AJWj6Wb","outputId":"c58e75d6-eb90-4fa7-9578-93892cf2817b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting nvcc4jupyter\n","  Downloading nvcc4jupyter-1.2.1-py3-none-any.whl.metadata (5.1 kB)\n","Downloading nvcc4jupyter-1.2.1-py3-none-any.whl (10 kB)\n","Installing collected packages: nvcc4jupyter\n","Successfully installed nvcc4jupyter-1.2.1\n","Collecting pycuda\n","  Downloading pycuda-2024.1.2.tar.gz (1.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m43.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Collecting pytools>=2011.2 (from pycuda)\n","  Downloading pytools-2024.1.11-py3-none-any.whl.metadata (3.0 kB)\n","Requirement already satisfied: platformdirs>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from pycuda) (4.2.2)\n","Collecting mako (from pycuda)\n","  Downloading Mako-1.3.5-py3-none-any.whl.metadata (2.9 kB)\n","Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from pytools>=2011.2->pycuda) (4.12.2)\n","Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from mako->pycuda) (2.1.5)\n","Downloading pytools-2024.1.11-py3-none-any.whl (88 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.2/88.2 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading Mako-1.3.5-py3-none-any.whl (78 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: pycuda\n","  Building wheel for pycuda (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pycuda: filename=pycuda-2024.1.2-cp310-cp310-linux_x86_64.whl size=662246 sha256=1ecc17e85dad1cb2f237ac86dc131bf5fca9f4214e6f11ad6aa2699cc8153142\n","  Stored in directory: /root/.cache/pip/wheels/70/63/40/4bf006182f942d3516b71bb2ff3b57ccbdb8b2c0ee81882b6e\n","Successfully built pycuda\n","Installing collected packages: pytools, mako, pycuda\n","Successfully installed mako-1.3.5 pycuda-2024.1.2 pytools-2024.1.11\n"]}],"source":["!pip install nvcc4jupyter\n","!pip install pycuda"]},{"cell_type":"markdown","metadata":{"id":"qBLCrwbmj6Wb"},"source":["GPU TYPE"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1722711145621,"user":{"displayName":"Sabrina Olivari","userId":"03563423152767973544"},"user_tz":-120},"id":"xYkG4idRj6Wb","outputId":"870d414f-0343-4e54-90d6-d3a27a5329ce"},"outputs":[{"name":"stdout","output_type":"stream","text":["Sat Aug  3 18:52:22 2024       \n","+---------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n","|-----------------------------------------+----------------------+----------------------+\n","| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                      |               MIG M. |\n","|=========================================+======================+======================|\n","|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n","| N/A   44C    P8               9W /  70W |      0MiB / 15360MiB |      0%      Default |\n","|                                         |                      |                  N/A |\n","+-----------------------------------------+----------------------+----------------------+\n","                                                                                         \n","+---------------------------------------------------------------------------------------+\n","| Processes:                                                                            |\n","|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n","|        ID   ID                                                             Usage      |\n","|=======================================================================================|\n","|  No running processes found                                                           |\n","+---------------------------------------------------------------------------------------+\n","nvcc: NVIDIA (R) Cuda compiler driver\n","Copyright (c) 2005-2023 NVIDIA Corporation\n","Built on Tue_Aug_15_22:02:13_PDT_2023\n","Cuda compilation tools, release 12.2, V12.2.140\n","Build cuda_12.2.r12.2/compiler.33191640_0\n","Detected platform \"Colab\". Running its setup...\n","Source files will be saved in \"/tmp/tmpz84ta14d\".\n"]}],"source":["!nvidia-smi\n","!nvcc --version\n","%load_ext nvcc4jupyter"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":515,"status":"ok","timestamp":1722711146129,"user":{"displayName":"Sabrina Olivari","userId":"03563423152767973544"},"user_tz":-120},"id":"HIJp4aitj6Wc","outputId":"11f4bba2-abfa-4da4-f0d1-9234ca2460ee"},"outputs":[{"name":"stdout","output_type":"stream","text":["1 device(s) found.\n","Device #0: Tesla T4\n"," Compute Capability: 7.5\n"," Total Memory: 14 GB\n"]}],"source":["import pycuda.driver as drv\n","import pycuda.autoinit\n","drv.init()\n","print(\"%d device(s) found.\" % drv.Device.count())\n","for i in range(drv.Device.count()):\n","  dev = drv.Device(i)\n","  print(\"Device #%d: %s\" % (i, dev.name()))\n","  print(\" Compute Capability: %d.%d\" % dev.compute_capability())\n","  print(\" Total Memory: %s GB\" % (dev.total_memory() // (1024 * 1024 * 1024)))"]},{"cell_type":"markdown","metadata":{"id":"1YG2FJsIj6Wc"},"source":["GPU INFO"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1531,"status":"ok","timestamp":1722711147657,"user":{"displayName":"Sabrina Olivari","userId":"03563423152767973544"},"user_tz":-120},"id":"M3NtaKiNj6Wc","outputId":"f88d02ed-1354-4c10-f8f0-99ff1dfd8b08"},"outputs":[{"name":"stdout","output_type":"stream","text":["Device number: 0\n","  Device name: Tesla T4\n","  Compute capability: 7.5\n","\n","  Clock Rate: 1590000 kHz\n","  Total SMs: 40 \n","  Shared Memory Per SM: 65536 bytes\n","  Registers Per SM: 65536 32-bit\n","  Max threads per SM: 1024\n","  L2 Cache Size: 4194304 bytes\n","  Total Global Memory: 15835660288 bytes\n","  Memory Clock Rate: 5001000 kHz\n","\n","  Max threads per block: 1024\n","  Max threads in X-dimension of block: 1024\n","  Max threads in Y-dimension of block: 1024\n","  Max threads in Z-dimension of block: 64\n","\n","  Max blocks in X-dimension of grid: 2147483647\n","  Max blocks in Y-dimension of grid: 65535\n","  Max blocks in Z-dimension of grid: 65535\n","\n","  Warp size: 32\n","\n"," Constant Memory: 65536\n"," Max resident blocks per SM: 16\n","\n"]}],"source":["%%cuda\n","\n","#include <stdio.h>\n","#include <stdlib.h>\n","\n","void deviceQuery()\n","{\n","  cudaDeviceProp prop;\n","  int nDevices=0, i;\n","  cudaError_t ierr;\n","\n","  ierr = cudaGetDeviceCount(&nDevices);\n","  if (ierr != cudaSuccess) { printf(\"Sync error: %s\\n\", cudaGetErrorString(ierr)); }\n","\n","\n","\n","  for( i = 0; i < nDevices; ++i )\n","  {\n","     ierr = cudaGetDeviceProperties(&prop, i);\n","     printf(\"Device number: %d\\n\", i);\n","     printf(\"  Device name: %s\\n\", prop.name);\n","     printf(\"  Compute capability: %d.%d\\n\\n\", prop.major, prop.minor);\n","\n","     printf(\"  Clock Rate: %d kHz\\n\", prop.clockRate);\n","     printf(\"  Total SMs: %d \\n\", prop.multiProcessorCount);\n","     printf(\"  Shared Memory Per SM: %lu bytes\\n\", prop.sharedMemPerMultiprocessor);\n","     printf(\"  Registers Per SM: %d 32-bit\\n\", prop.regsPerMultiprocessor);\n","     printf(\"  Max threads per SM: %d\\n\", prop.maxThreadsPerMultiProcessor);\n","     printf(\"  L2 Cache Size: %d bytes\\n\", prop.l2CacheSize);\n","     printf(\"  Total Global Memory: %lu bytes\\n\", prop.totalGlobalMem);\n","     printf(\"  Memory Clock Rate: %d kHz\\n\\n\", prop.memoryClockRate);\n","\n","\n","     printf(\"  Max threads per block: %d\\n\", prop.maxThreadsPerBlock);\n","     printf(\"  Max threads in X-dimension of block: %d\\n\", prop.maxThreadsDim[0]);\n","     printf(\"  Max threads in Y-dimension of block: %d\\n\", prop.maxThreadsDim[1]);\n","     printf(\"  Max threads in Z-dimension of block: %d\\n\\n\", prop.maxThreadsDim[2]);\n","\n","     printf(\"  Max blocks in X-dimension of grid: %d\\n\", prop.maxGridSize[0]);\n","     printf(\"  Max blocks in Y-dimension of grid: %d\\n\", prop.maxGridSize[1]);\n","     printf(\"  Max blocks in Z-dimension of grid: %d\\n\\n\", prop.maxGridSize[2]);\n","\n","     printf(\"  Warp size: %d\\n\\n\", prop.warpSize);\n","     printf(\" Constant Memory: %d\\n\", prop.totalConstMem);\n","     printf(\" Max resident blocks per SM: %d\\n\", prop.maxBlocksPerMultiProcessor);\n","  }\n","}\n","\n","int main() {\n","    deviceQuery();\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ui8H7vkPj6Wd"},"outputs":[],"source":["!make clean\n","!make"]},{"cell_type":"markdown","metadata":{"id":"IUWPiq-Tj6Wd"},"source":["CHOOSE THE BEST OPTIMIZATION ON RANDOM GRAPH OF DIFFERENT SIZES"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wBXFt35Zj6Wd"},"outputs":[],"source":["graph_dimension = [3000, 5000, 8000, 10000]\n","optimizations = ['O0','O1','O2','O3']\n","\n","for opt in optimizations:\n","    for dim in graph_dimension:\n","        cmd_sequential = f\"./vf2pp_sequential_{opt} {dim} 3\"\n","        cmd_parallel = f\"./vf2pp_parallel_{opt} {dim} 3\"\n","        !{cmd_sequential}\n","        !{cmd_parallel}"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":400,"status":"ok","timestamp":1722714773508,"user":{"displayName":"Sabrina Olivari","userId":"03563423152767973544"},"user_tz":-120},"id":"siLWAXyFj6We","outputId":"0ca2f450-ebc8-4490-e018-1886556127d1"},"outputs":[{"name":"stdout","output_type":"stream","text":["                  OPTIMIZATION 0  OPTIMIZATION 1  OPTIMIZATION 2  \\\n","Sequential Means     1046.065460      551.812976      567.564568   \n","Parallel Means         19.479678       19.111196       19.600804   \n","\n","                  OPTIMIZATION 3  \n","Sequential Means      678.450359  \n","Parallel Means         19.885869  \n"]}],"source":["'''\n","Each file name is of the type \"result_{dim}_3.txt\" so each file will contain 4 values, one for each optimization performed.\n","So each file represents the execution times on the graph of size \"dim\" with different optimizations.\n","We begin by running the simulation, and then, for each optimization, we calculate the average execution time across all dimensions of the graph.\n","The best optimization is the O1 for both sequential and parallel versions.\n","'''\n","\n","import os\n","\n","def read_files(directory):\n","    measures = {0: [], 1: [], 2: [], 3: []}\n","\n","    files = os.listdir(directory)\n","\n","    for file in files:\n","        with open(os.path.join(directory, file), 'r') as f:\n","            line = f.read()\n","            times = line.split()\n","            for i, time in enumerate(times):\n","                measures[i].append(float(time))\n","\n","    return measures\n","\n","def calculate_means(measures):\n","    means = []\n","\n","    for key, values in measures.items():\n","        mean = sum(values) / len(values)\n","        means.append(mean)\n","\n","    return means\n","\n","seq_measures = read_files(\"./benchmark/measures/optimizations/sequential/\")\n","par_measures = read_files(\"./benchmark/measures/optimizations/parallel/\")\n","\n","seq_means = calculate_means(seq_measures)\n","par_means = calculate_means(par_measures)\n","\n","import pandas as pd\n","\n","data = {\n","    \"OPTIMIZATION 0\": [seq_means[0], par_means[0]],\n","    \"OPTIMIZATION 1\": [seq_means[1], par_means[1]],\n","    \"OPTIMIZATION 2\": [seq_means[2], par_means[2]],\n","    \"OPTIMIZATION 3\": [seq_means[3], par_means[3]],\n","}\n","\n","df = pd.DataFrame(data, index=[\"Sequential Means\", \"Parallel Means\"])\n","\n","output_directory = \"./benchmark/measures/optimizations\"\n","output_file = os.path.join(output_directory, \"opt_means_results.csv\")\n","df.to_csv(output_file)\n","\n","print(df)\n"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
