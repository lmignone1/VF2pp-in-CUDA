{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":36827,"status":"ok","timestamp":1720436701782,"user":{"displayName":"LORENZO MIGNONE","userId":"02647048791547825809"},"user_tz":-120},"id":"OVKsPm9V3gQL","outputId":"a2744fdb-dc3d-4d66-bcd0-09a699414bdd"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","import os\n","\n","drive.mount('/content/drive')\n","os.chdir(\"drive/Othercomputers/pc/VF2pp-in-CUDA/\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":416,"status":"ok","timestamp":1720434007641,"user":{"displayName":"LORENZO MIGNONE","userId":"02647048791547825809"},"user_tz":-120},"id":"_IbccJNAcjIa","outputId":"aaf4d3fd-4a6c-4807-fc50-c9a6cb0d82ac"},"outputs":[{"name":"stdout","output_type":"stream","text":["rm -f src/lib/stack.o src/lib/queue.o src/lib/graph.o src/lib/state.o src/vf2pp_sequential.o vf2pp_sequential\n"]}],"source":["os.listdir()\n","!make clean"]},{"cell_type":"markdown","metadata":{"id":"h498tzxnwDyi"},"source":["CUDA SETUP"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":154617,"status":"ok","timestamp":1720436856395,"user":{"displayName":"LORENZO MIGNONE","userId":"02647048791547825809"},"user_tz":-120},"id":"rbh20Z5utmFQ","outputId":"45d14275-8897-4274-d0b8-99938a7adc36"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting nvcc4jupyter\n","  Downloading nvcc4jupyter-1.2.1-py3-none-any.whl (10 kB)\n","Installing collected packages: nvcc4jupyter\n","Successfully installed nvcc4jupyter-1.2.1\n","Collecting pycuda\n","  Downloading pycuda-2024.1.tar.gz (1.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Collecting pytools>=2011.2 (from pycuda)\n","  Downloading pytools-2024.1.6-py2.py3-none-any.whl (88 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.6/88.6 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting appdirs>=1.4.0 (from pycuda)\n","  Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n","Collecting mako (from pycuda)\n","  Downloading Mako-1.3.5-py3-none-any.whl (78 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: platformdirs>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from pytools>=2011.2->pycuda) (4.2.2)\n","Requirement already satisfied: typing-extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from pytools>=2011.2->pycuda) (4.12.2)\n","Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from mako->pycuda) (2.1.5)\n","Building wheels for collected packages: pycuda\n","  Building wheel for pycuda (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pycuda: filename=pycuda-2024.1-cp310-cp310-linux_x86_64.whl size=661206 sha256=6ac4edfa940bfabbabfe34ba41560d5050af8c1c0991f69492421da8a4e4013f\n","  Stored in directory: /root/.cache/pip/wheels/12/34/d2/9a349255a4eca3a486d82c79d21e138ce2ccd90f414d9d72b8\n","Successfully built pycuda\n","Installing collected packages: appdirs, pytools, mako, pycuda\n","Successfully installed appdirs-1.4.4 mako-1.3.5 pycuda-2024.1 pytools-2024.1.6\n"]}],"source":["!pip install nvcc4jupyter\n","!pip install pycuda"]},{"cell_type":"markdown","metadata":{"id":"8_P-CD0hwSmY"},"source":["GPU TYPE"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":630,"status":"ok","timestamp":1720436857013,"user":{"displayName":"LORENZO MIGNONE","userId":"02647048791547825809"},"user_tz":-120},"id":"ntofwbc0tEKS","outputId":"bd0b02bb-26e4-4fe5-856c-a9f625537b81"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mon Jul  8 11:07:36 2024       \n","+---------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n","|-----------------------------------------+----------------------+----------------------+\n","| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                      |               MIG M. |\n","|=========================================+======================+======================|\n","|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n","| N/A   52C    P8              10W /  70W |      0MiB / 15360MiB |      0%      Default |\n","|                                         |                      |                  N/A |\n","+-----------------------------------------+----------------------+----------------------+\n","                                                                                         \n","+---------------------------------------------------------------------------------------+\n","| Processes:                                                                            |\n","|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n","|        ID   ID                                                             Usage      |\n","|=======================================================================================|\n","|  No running processes found                                                           |\n","+---------------------------------------------------------------------------------------+\n","nvcc: NVIDIA (R) Cuda compiler driver\n","Copyright (c) 2005-2023 NVIDIA Corporation\n","Built on Tue_Aug_15_22:02:13_PDT_2023\n","Cuda compilation tools, release 12.2, V12.2.140\n","Build cuda_12.2.r12.2/compiler.33191640_0\n","Detected platform \"Colab\". Running its setup...\n","Source files will be saved in \"/tmp/tmphowjga81\".\n"]}],"source":["!nvidia-smi\n","!nvcc --version\n","%load_ext nvcc4jupyter"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1720436857013,"user":{"displayName":"LORENZO MIGNONE","userId":"02647048791547825809"},"user_tz":-120},"id":"KfQ4iKK_p0hY","outputId":"67de1cce-ea1d-4a9f-e6a6-9b17047575aa"},"outputs":[{"name":"stdout","output_type":"stream","text":["1 device(s) found.\n","Device #0: Tesla T4\n"," Compute Capability: 7.5\n"," Total Memory: 14 GB\n"]}],"source":["import pycuda.driver as drv\n","import pycuda.autoinit\n","drv.init()\n","print(\"%d device(s) found.\" % drv.Device.count())\n","for i in range(drv.Device.count()):\n","  dev = drv.Device(i)\n","  print(\"Device #%d: %s\" % (i, dev.name()))\n","  print(\" Compute Capability: %d.%d\" % dev.compute_capability())\n","  print(\" Total Memory: %s GB\" % (dev.total_memory() // (1024 * 1024 * 1024)))"]},{"cell_type":"markdown","metadata":{"id":"8X72on3Cwj7C"},"source":["GPU INFO"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2553,"status":"ok","timestamp":1719513753594,"user":{"displayName":"LORENZO MIGNONE","userId":"02647048791547825809"},"user_tz":-120},"id":"u9x2_pq4wwyI","outputId":"74d0aeb9-0451-4315-b098-dddb821e9438"},"outputs":[{"name":"stdout","output_type":"stream","text":["Device number: 0\n","  Device name: Tesla T4\n","  Compute capability: 7.5\n","\n","  Clock Rate: 1590000 kHz\n","  Total SMs: 40 \n","  Shared Memory Per SM: 65536 bytes\n","  Registers Per SM: 65536 32-bit\n","  Max threads per SM: 1024\n","  L2 Cache Size: 4194304 bytes\n","  Total Global Memory: 15835660288 bytes\n","  Memory Clock Rate: 5001000 kHz\n","\n","  Max threads per block: 1024\n","  Max threads in X-dimension of block: 1024\n","  Max threads in Y-dimension of block: 1024\n","  Max threads in Z-dimension of block: 64\n","\n","  Max blocks in X-dimension of grid: 2147483647\n","  Max blocks in Y-dimension of grid: 65535\n","  Max blocks in Z-dimension of grid: 65535\n","\n","  Shared Memory Per Block: 49152 bytes\n","  Registers Per Block: 65536 32-bit\n","  Warp size: 32\n","\n","\n"]}],"source":["%%cuda\n","\n","#include <stdio.h>\n","#include <stdlib.h>\n","\n","void deviceQuery()\n","{\n","  cudaDeviceProp prop;\n","  int nDevices=0, i;\n","  cudaError_t ierr;\n","\n","  ierr = cudaGetDeviceCount(&nDevices);\n","  if (ierr != cudaSuccess) { printf(\"Sync error: %s\\n\", cudaGetErrorString(ierr)); }\n","\n","\n","\n","  for( i = 0; i < nDevices; ++i )\n","  {\n","     ierr = cudaGetDeviceProperties(&prop, i);\n","     printf(\"Device number: %d\\n\", i);\n","     printf(\"  Device name: %s\\n\", prop.name);\n","     printf(\"  Compute capability: %d.%d\\n\\n\", prop.major, prop.minor);\n","\n","     printf(\"  Clock Rate: %d kHz\\n\", prop.clockRate);\n","     printf(\"  Total SMs: %d \\n\", prop.multiProcessorCount);\n","     printf(\"  Shared Memory Per SM: %lu bytes\\n\", prop.sharedMemPerMultiprocessor);\n","     printf(\"  Registers Per SM: %d 32-bit\\n\", prop.regsPerMultiprocessor);\n","     printf(\"  Max threads per SM: %d\\n\", prop.maxThreadsPerMultiProcessor);\n","     printf(\"  L2 Cache Size: %d bytes\\n\", prop.l2CacheSize);\n","     printf(\"  Total Global Memory: %lu bytes\\n\", prop.totalGlobalMem);\n","     printf(\"  Memory Clock Rate: %d kHz\\n\\n\", prop.memoryClockRate);\n","\n","\n","     printf(\"  Max threads per block: %d\\n\", prop.maxThreadsPerBlock);\n","     printf(\"  Max threads in X-dimension of block: %d\\n\", prop.maxThreadsDim[0]);\n","     printf(\"  Max threads in Y-dimension of block: %d\\n\", prop.maxThreadsDim[1]);\n","     printf(\"  Max threads in Z-dimension of block: %d\\n\\n\", prop.maxThreadsDim[2]);\n","\n","     printf(\"  Max blocks in X-dimension of grid: %d\\n\", prop.maxGridSize[0]);\n","     printf(\"  Max blocks in Y-dimension of grid: %d\\n\", prop.maxGridSize[1]);\n","     printf(\"  Max blocks in Z-dimension of grid: %d\\n\\n\", prop.maxGridSize[2]);\n","\n","     printf(\"  Shared Memory Per Block: %lu bytes\\n\", prop.sharedMemPerBlock);\n","     printf(\"  Registers Per Block: %d 32-bit\\n\", prop.regsPerBlock);\n","     printf(\"  Warp size: %d\\n\\n\", prop.warpSize);\n","\n","  }\n","}\n","\n","int main() {\n","    deviceQuery();\n","}"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4218,"status":"ok","timestamp":1720436964969,"user":{"displayName":"LORENZO MIGNONE","userId":"02647048791547825809"},"user_tz":-120},"id":"8japRd-9Hqws","outputId":"6cf6b026-1477-46a5-f940-73df26390cef"},"outputs":[{"name":"stdout","output_type":"stream","text":["+4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 +4 Graphs are isomorphic\n","Mapping\n","0 -> 0\n","1 -> 1\n","2 -> 2\n","3 -> 3\n","4 -> 4\n","5 -> 5\n","6 -> 6\n","7 -> 7\n","8 -> 8\n","9 -> 9\n","10 -> 10\n","11 -> 11\n","12 -> 12\n","13 -> 13\n","14 -> 14\n","15 -> 15\n","16 -> 16\n","17 -> 17\n","18 -> 18\n","19 -> 19\n","20 -> 20\n","21 -> 21\n","22 -> 22\n","23 -> 23\n","24 -> 24\n","25 -> 25\n","26 -> 26\n","27 -> 27\n","28 -> 28\n","29 -> 29\n","30 -> 30\n","31 -> 31\n","32 -> 32\n","33 -> 33\n","34 -> 34\n","35 -> 35\n","36 -> 36\n","37 -> 37\n","38 -> 38\n","39 -> 39\n","40 -> 40\n","41 -> 41\n","42 -> 42\n","43 -> 43\n","44 -> 44\n","45 -> 45\n","46 -> 46\n","47 -> 47\n","48 -> 48\n","49 -> 49\n","50 -> 50\n","51 -> 51\n","52 -> 52\n","53 -> 53\n","54 -> 54\n","55 -> 55\n","56 -> 56\n","57 -> 57\n","58 -> 58\n","59 -> 59\n","60 -> 60\n","61 -> 61\n","62 -> 62\n","63 -> 63\n","64 -> 64\n","65 -> 65\n","66 -> 66\n","67 -> 67\n","68 -> 68\n","69 -> 69\n","70 -> 70\n","71 -> 71\n","72 -> 72\n","73 -> 73\n","74 -> 74\n","75 -> 75\n","76 -> 76\n","77 -> 77\n","78 -> 78\n","79 -> 79\n","80 -> 80\n","81 -> 81\n","82 -> 82\n","83 -> 83\n","84 -> 84\n","85 -> 85\n","86 -> 86\n","87 -> 87\n","88 -> 88\n","89 -> 89\n","90 -> 90\n","91 -> 91\n","92 -> 92\n","93 -> 93\n","94 -> 94\n","95 -> 95\n","96 -> 96\n","97 -> 97\n","98 -> 98\n","99 -> 99\n","100 -> 100\n","101 -> 101\n","102 -> 102\n","103 -> 103\n","104 -> 104\n","105 -> 105\n","106 -> 106\n","107 -> 107\n","108 -> 108\n","109 -> 109\n","110 -> 110\n","111 -> 111\n","112 -> 112\n","113 -> 113\n","114 -> 114\n","115 -> 115\n","116 -> 116\n","117 -> 117\n","118 -> 118\n","119 -> 119\n","120 -> 120\n","121 -> 121\n","122 -> 122\n","123 -> 123\n","124 -> 124\n","125 -> 125\n","126 -> 126\n","127 -> 127\n","128 -> 128\n","129 -> 129\n","130 -> 130\n","131 -> 131\n","132 -> 132\n","133 -> 133\n","134 -> 134\n","135 -> 135\n","136 -> 136\n","137 -> 137\n","138 -> 138\n","139 -> 139\n","140 -> 140\n","141 -> 141\n","142 -> 142\n","143 -> 143\n","144 -> 144\n","145 -> 145\n","146 -> 146\n","147 -> 147\n","148 -> 148\n","149 -> 149\n","150 -> 150\n","151 -> 151\n","152 -> 152\n","153 -> 153\n","154 -> 154\n","155 -> 155\n","156 -> 156\n","157 -> 157\n","158 -> 158\n","159 -> 159\n","160 -> 160\n","161 -> 161\n","162 -> 162\n","163 -> 163\n","164 -> 164\n","165 -> 165\n","166 -> 166\n","167 -> 167\n","168 -> 168\n","169 -> 169\n","170 -> 170\n","171 -> 171\n","172 -> 172\n","173 -> 173\n","174 -> 174\n","175 -> 175\n","176 -> 176\n","177 -> 177\n","178 -> 178\n","179 -> 179\n","180 -> 180\n","181 -> 181\n","182 -> 182\n","183 -> 183\n","184 -> 184\n","185 -> 185\n","186 -> 186\n","187 -> 187\n","188 -> 188\n","189 -> 189\n","190 -> 190\n","191 -> 191\n","192 -> 192\n","193 -> 193\n","194 -> 194\n","195 -> 195\n","196 -> 196\n","197 -> 197\n","198 -> 198\n","199 -> 199\n","200 -> 200\n","201 -> 201\n","202 -> 202\n","203 -> 203\n","204 -> 204\n","205 -> 205\n","206 -> 206\n","207 -> 207\n","208 -> 208\n","209 -> 209\n","210 -> 210\n","211 -> 211\n","212 -> 212\n","213 -> 213\n","214 -> 214\n","215 -> 215\n","216 -> 216\n","217 -> 217\n","218 -> 218\n","219 -> 219\n","220 -> 220\n","221 -> 221\n","222 -> 222\n","223 -> 223\n","224 -> 224\n","225 -> 225\n","226 -> 226\n","227 -> 227\n","228 -> 228\n","229 -> 229\n","230 -> 230\n","231 -> 231\n","232 -> 232\n","233 -> 233\n","234 -> 234\n","235 -> 235\n","236 -> 236\n","237 -> 237\n","238 -> 238\n","239 -> 239\n","240 -> 240\n","241 -> 241\n","242 -> 242\n","243 -> 243\n","244 -> 244\n","245 -> 245\n","246 -> 246\n","247 -> 247\n","248 -> 248\n","249 -> 249\n","250 -> 250\n","251 -> 251\n","252 -> 252\n","253 -> 253\n","254 -> 254\n","255 -> 255\n","256 -> 256\n","257 -> 257\n","258 -> 258\n","259 -> 259\n","260 -> 260\n","261 -> 261\n","262 -> 262\n","263 -> 263\n","264 -> 264\n","265 -> 265\n","266 -> 266\n","267 -> 267\n","268 -> 268\n","269 -> 269\n","270 -> 270\n","271 -> 271\n","272 -> 272\n","273 -> 273\n","274 -> 274\n","275 -> 275\n","276 -> 276\n","277 -> 277\n","278 -> 278\n","279 -> 279\n","280 -> 280\n","281 -> 281\n","282 -> 282\n","283 -> 283\n","284 -> 284\n","285 -> 285\n","286 -> 286\n","287 -> 287\n","288 -> 288\n","289 -> 289\n","290 -> 290\n","291 -> 291\n","292 -> 292\n","293 -> 293\n","294 -> 294\n","295 -> 295\n","296 -> 296\n","297 -> 297\n","298 -> 298\n","299 -> 299\n","300 -> 300\n","301 -> 301\n","302 -> 302\n","303 -> 303\n","304 -> 304\n","305 -> 305\n","306 -> 306\n","307 -> 307\n","308 -> 308\n","309 -> 309\n","310 -> 310\n","311 -> 311\n","312 -> 312\n","313 -> 313\n","314 -> 314\n","315 -> 315\n","316 -> 316\n","317 -> 317\n","318 -> 318\n","319 -> 319\n","320 -> 320\n","321 -> 321\n","322 -> 322\n","323 -> 323\n","324 -> 324\n","325 -> 325\n","326 -> 326\n","327 -> 327\n","328 -> 328\n","329 -> 329\n","330 -> 330\n","331 -> 331\n","332 -> 332\n","333 -> 333\n","334 -> 334\n","335 -> 335\n","336 -> 336\n","337 -> 337\n","338 -> 338\n","339 -> 339\n","340 -> 340\n","341 -> 341\n","342 -> 342\n","343 -> 343\n","344 -> 344\n","345 -> 345\n","346 -> 346\n","347 -> 347\n","348 -> 348\n","349 -> 349\n","350 -> 350\n","351 -> 351\n","352 -> 352\n","353 -> 353\n","354 -> 354\n","355 -> 355\n","356 -> 356\n","357 -> 357\n","358 -> 358\n","359 -> 359\n","360 -> 360\n","361 -> 361\n","362 -> 362\n","363 -> 363\n","364 -> 364\n","365 -> 365\n","366 -> 366\n","367 -> 367\n","368 -> 368\n","369 -> 369\n","370 -> 370\n","371 -> 371\n","372 -> 372\n","373 -> 373\n","374 -> 374\n","375 -> 375\n","376 -> 376\n","377 -> 377\n","378 -> 378\n","379 -> 379\n","380 -> 380\n","381 -> 381\n","382 -> 382\n","383 -> 383\n","384 -> 384\n","385 -> 385\n","386 -> 386\n","387 -> 387\n","388 -> 388\n","389 -> 389\n","390 -> 390\n","391 -> 391\n","392 -> 392\n","393 -> 393\n","394 -> 394\n","395 -> 395\n","396 -> 396\n","397 -> 397\n","398 -> 398\n","399 -> 399\n","400 -> 400\n","401 -> 401\n","402 -> 402\n","403 -> 403\n","404 -> 404\n","405 -> 405\n","406 -> 406\n","407 -> 407\n","408 -> 408\n","409 -> 409\n","410 -> 410\n","411 -> 411\n","412 -> 412\n","413 -> 413\n","414 -> 414\n","415 -> 415\n","416 -> 416\n","417 -> 417\n","418 -> 418\n","419 -> 419\n","420 -> 420\n","421 -> 421\n","422 -> 422\n","423 -> 423\n","424 -> 424\n","425 -> 425\n","426 -> 426\n","427 -> 427\n","428 -> 428\n","429 -> 429\n","430 -> 430\n","431 -> 431\n","432 -> 432\n","433 -> 433\n","434 -> 434\n","435 -> 435\n","436 -> 436\n","437 -> 437\n","438 -> 438\n","439 -> 439\n","440 -> 440\n","441 -> 441\n","442 -> 442\n","443 -> 443\n","444 -> 444\n","445 -> 445\n","446 -> 446\n","447 -> 447\n","448 -> 448\n","449 -> 449\n","450 -> 450\n","451 -> 451\n","452 -> 452\n","453 -> 453\n","454 -> 454\n","455 -> 455\n","456 -> 456\n","457 -> 457\n","458 -> 458\n","459 -> 459\n","460 -> 460\n","461 -> 461\n","462 -> 462\n","463 -> 463\n","464 -> 464\n","465 -> 465\n","466 -> 466\n","467 -> 467\n","468 -> 468\n","469 -> 469\n","470 -> 470\n","471 -> 471\n","472 -> 472\n","473 -> 473\n","474 -> 474\n","475 -> 475\n","476 -> 476\n","477 -> 477\n","478 -> 478\n","479 -> 479\n","480 -> 480\n","481 -> 481\n","482 -> 482\n","483 -> 483\n","484 -> 484\n","485 -> 485\n","486 -> 486\n","487 -> 487\n","488 -> 488\n","489 -> 489\n","490 -> 490\n","491 -> 491\n","492 -> 492\n","493 -> 493\n","494 -> 494\n","495 -> 495\n","496 -> 496\n","497 -> 497\n","498 -> 498\n","499 -> 499\n","\n"]}],"source":["%%cuda\n","#include <stdio.h>\n","#include <stdlib.h>\n","#include <stdbool.h>\n","#include <cuda_runtime.h>\n","#include <limits.h>\n","#include <string.h>\n","\n","#define FILENAME_QUERY \"data/graph_query_500.csv\"\n","#define FILENAME_TARGET \"data/graph_target_500.csv\"\n","#define LABELS 10\n","#define INF 99999\n","\n","int blockSize;\n","__constant__ int constMem[];\n","\n","#define CUDA_CHECK_ERROR(err)           \\\n","    if (err != cudaSuccess) {            \\\n","        printf(\"CUDA error: %s\\n\", cudaGetErrorString(err)); \\\n","        printf(\"Error in file: %s, line: %i\\n\", __FILE__, __LINE__); \\\n","        exit(EXIT_FAILURE);              \\\n","    }\n","\n","/***** STRUCTS *****/\n","typedef struct {\n","    int* matrix;\n","    int numVertices;\n","    int* nodesToLabel;\n","    int** labelToNodes;\n","    int* labelsCardinalities;\n","    int* degrees;\n","} Graph;\n","\n","typedef struct {\n","    int *mapping1;  // mapping from query to target\n","    int *mapping2;  // mapping from target to query\n","    int *T1;        // Ti contains uncovered neighbors of covered nodes from Gi, i.e. nodes that are not in the mapping, but are neighbors of nodes that are.\n","    int *T2;\n","    int* T1_out;     //Ti_out contains all the nodes from Gi, that are neither in the mapping nor in Ti. Cioe nodi che non sono in mapping e non sono vicini di nodi coperti\n","    int* T2_out;\n","} State;\n","\n","typedef struct {\n","    int vertex;\n","    int* candidates;\n","    int sizeCandidates;\n","    int candidateIndex;\n","} Info;\n","\n","typedef struct StackNode {\n","    Info* info;\n","    struct StackNode* next;\n","} StackNode;\n","\n","/***** GRAPH PROTOTYPES *****/\n","void initGraph(Graph*);\n","Graph* createGraph();\n","void addEdge(Graph*, int, int);\n","Graph* readGraph(char*);\n","void printGraph(Graph*);\n","void freeGraph(Graph*);\n","void setLabel(Graph*, int, int);\n","\n","/***** STATE PROTOTYPES *****/\n","State* createState(Graph*, Graph*);\n","void freeState(State*);\n","void printState(State*, int);\n","bool isMappingFull(Graph*, State*);\n","void updateState(Graph*, Graph*, State*, int, int);\n","void restoreState(Graph*, Graph*, State*, int, int);\n","\n","/***** VF2++ PROTOTYPES *****/\n","void vf2pp(Graph*, Graph*, State*);\n","bool checkGraphProperties(Graph*, Graph*);\n","bool checkSequenceDegree(int*, int*, int);\n","int compare(const void*, const void*);\n","int* ordering(Graph*, Graph*);\n","int* bfs(Graph*, int, int*);\n","int findRoot(int, int*, int*, int*);\n","void processDepth(int*, int*, int*, int*, int*, int*, int, int*, int*, int*, int*);\n","int* findCandidates(Graph*, Graph*, State*, int, int*);\n","bool cutISO(Graph*, Graph*, State*, int, int);\n","\n","/***** STACK PROTOTYPES *****/\n","Info* createInfo(int* candidates, int sizeCandidates, int vertex);\n","StackNode* createStackNode(Info*);\n","void push(StackNode**, Info*);\n","Info* pop(StackNode**);\n","bool isStackEmpty(StackNode*);\n","void freeStack(StackNode*);\n","void printStack(StackNode*);\n","void printInfo(Info*);\n","void freeInfo(Info*);\n","StackNode* createStack();\n","Info* peek(StackNode**);\n","\n","int main() {\n","    blockSize = 4;\n","\n","    // printf(\"%s\\n\", FILENAME_QUERY);\n","    Graph* g1 = readGraph(FILENAME_QUERY);\n","    // printf(\"%s\\n\", FILENAME_TARGET);\n","    Graph* g2 = readGraph(FILENAME_TARGET);\n","    State* s = createState(g1, g2);\n","\n","    // printf(\"\\n\");\n","    // printState(s, g1->numVertices);\n","    // printf(\"\\n\");\n","\n","    vf2pp(g1, g2, s);\n","\n","     printf(\"Mapping\\n\");\n","     for(int i = 0; i < g1->numVertices; i++) {\n","         printf(\"%d -> %d\\n\", i, s->mapping1[i]);\n","     }\n","\n","    freeGraph(g1);\n","    freeGraph(g2);\n","    freeState(s);\n","\n","    return EXIT_SUCCESS;\n","}\n","\n","/***** GRAPH FUNCTIONS *****/\n","void initGraph(Graph* g) {\n","    g->matrix = (int*)malloc(g->numVertices * g->numVertices * sizeof(int));\n","    g->nodesToLabel = (int*)malloc(g->numVertices * sizeof(int));\n","    g->labelsCardinalities = (int*)malloc(LABELS * sizeof(int));\n","    g->labelToNodes = (int**)malloc(LABELS * sizeof(int*));\n","    g->degrees = (int*)malloc(g->numVertices * sizeof(int));\n","\n","    if (g->nodesToLabel == NULL || g->labelsCardinalities == NULL || g->labelToNodes == NULL || g->degrees == NULL || g->matrix == NULL) {\n","        printf(\"Error allocating memory in initGraph\\n\");\n","        exit(EXIT_FAILURE);\n","    }\n","\n","    for (int vertex = 0; vertex < g->numVertices; vertex++) {\n","        g->nodesToLabel[vertex] = -1;\n","        g->degrees[vertex] = 0;\n","\n","        for (int adjVertex = 0; adjVertex < g->numVertices; adjVertex++) {\n","            g->matrix[vertex * g->numVertices + adjVertex] = 0;\n","        }\n","    }\n","\n","    for (int label = 0; label < LABELS; label++) {\n","        g->labelsCardinalities[label] = 0;\n","        g->labelToNodes[label] = (int*)malloc(g->numVertices * sizeof(int));\n","    }\n","}\n","\n","void setLabel(Graph* g, int node, int label) {\n","    if (g->nodesToLabel[node] == -1) {\n","        g->nodesToLabel[node] = label;\n","        g->labelsCardinalities[label]++;\n","        g->labelToNodes[label][g->labelsCardinalities[label] - 1] = node;\n","    }\n","}\n","\n","void addEdge(Graph* g, int src, int target) {\n","    g->matrix[src * g->numVertices + target] = 1;\n","    g->matrix[target * g->numVertices + src] = 1;\n","    g->degrees[src]++;\n","    g->degrees[target]++;\n","}\n","\n","Graph* createGraph() {\n","    Graph* g = (Graph*)malloc(sizeof(Graph));\n","\n","    if (g == NULL) {\n","        printf(\"Error allocating memory in createGraph\\n\");\n","        exit(EXIT_FAILURE);\n","    }\n","\n","    g->matrix = NULL;\n","    g->numVertices = 0;\n","    g->nodesToLabel = NULL;\n","    g->labelsCardinalities = NULL;\n","    g->degrees = NULL;\n","    g->labelToNodes = NULL;\n","    return g;\n","}\n","\n","Graph* readGraph(char* path) {\n","    int src, target, srcLabel, targetLabel;\n","    Graph* g = createGraph();\n","\n","    FILE* f = fopen(path, \"r\");\n","    if (f == NULL) {\n","        printf(\"Error opening file\\n\");\n","        exit(EXIT_FAILURE);\n","    }\n","\n","    char line[128];\n","    fgets(line, sizeof(line), f);\n","    sscanf(line, \"%*s%*s%*s%d\", &g->numVertices);\n","    fgets(line, sizeof(line), f); // skip the header\n","\n","    initGraph(g);\n","\n","    while (fgets(line, sizeof(line), f)) {\n","        sscanf(line, \"%d,%d,%d,%d\", &src, &target, &srcLabel, &targetLabel);\n","        addEdge(g, src, target);\n","        setLabel(g, src, srcLabel);\n","        setLabel(g, target, targetLabel);\n","    }\n","\n","    fclose(f);\n","\n","    for(int label = 0; label < LABELS; label++) {\n","        g->labelToNodes[label] = (int*)realloc(g->labelToNodes[label], g->labelsCardinalities[label] * sizeof(int));\n","    }\n","\n","    return g;\n","}\n","\n","void printGraph(Graph* g) {\n","    for (int i = 0; i < g->numVertices; i++) {\n","        for (int j = 0; j < g->numVertices; j++) {\n","            printf(\"%d \", g->matrix[i * g->numVertices + j]);\n","        }\n","        printf(\"\\tVertex %d, label %d, degree %d\\n\", i, g->nodesToLabel[i], g->degrees[i]);\n","    }\n","\n","    printf(\"\\nCardinalities\\n\");\n","    for (int i = 0; i < LABELS; i++) {\n","        printf(\"Label %d: %d\\n\", i, g->labelsCardinalities[i]);\n","    }\n","\n","    for(int i = 0; i < LABELS; i++) {\n","       printf(\"\\nLabel %d\\n\", i);\n","       for(int j = 0; j < g->labelsCardinalities[i]; j++) {\n","           printf(\"%d \", g->labelToNodes[i][j]);\n","       }\n","    }\n","}\n","\n","void freeGraph(Graph* g) {\n","    for(int i = 0; i < LABELS; i++) {\n","        free(g->labelToNodes[i]);\n","    }\n","    free(g->labelToNodes);\n","    free(g->matrix);\n","    free(g->nodesToLabel);\n","    free(g->labelsCardinalities);\n","    free(g->degrees);\n","    free(g);\n","    g = NULL;\n","}\n","\n","/***** STATE FUNCTIONS *****/\n","State* createState(Graph* g1, Graph* g2) {\n","    State* s = (State*)malloc(sizeof(State));\n","\n","    s->mapping1 = (int*)malloc(g1->numVertices * sizeof(int));\n","    s->mapping2 = (int*)malloc(g2->numVertices * sizeof(int));\n","    s->T1 = (int*)malloc(g1->numVertices * sizeof(int));\n","    s->T2 = (int*)malloc(g2->numVertices * sizeof(int));\n","    s->T1_out = (int*)malloc(g1->numVertices * sizeof(int));\n","    s->T2_out = (int*)malloc(g2->numVertices * sizeof(int));\n","\n","    if (s == NULL || s->mapping1 == NULL || s->mapping2 == NULL || s->T1 == NULL || s->T2 == NULL || s->T1_out == NULL || s->T2_out == NULL) {\n","        printf(\"Error allocating memory in createState\\n\");\n","        exit(EXIT_FAILURE);\n","    }\n","\n","    for (int i = 0; i < g1->numVertices; i++) {\n","        s->mapping1[i] = -1;\n","        s->T1[i] = -1;\n","        s->T1_out[i] = 1;\n","\n","        s->mapping2[i] = -1;\n","        s->T2[i] = -1;\n","        s->T2_out[i] = 1;\n","    }\n","\n","    return s;\n","}\n","\n","void freeState(State* s) {\n","    free(s->mapping1);\n","    free(s->mapping2);\n","    free(s->T1);\n","    free(s->T2);\n","    free(s->T1_out);\n","    free(s->T2_out);\n","    free(s);\n","    s = NULL;\n","}\n","\n","void printState(State* s, int numVertices) {\n","    printf(\"Mapping 1\\n\");\n","    for (int i = 0; i < numVertices; i++) {\n","        printf(\"%d \", s->mapping1[i]);\n","    }\n","\n","    printf(\"\\nMapping 2\\n\");\n","    for (int i = 0; i < numVertices; i++) {\n","        printf(\"%d \", s->mapping2[i]);\n","    }\n","\n","    printf(\"\\nT1\\n\");\n","    for (int i = 0; i < numVertices; i++) {\n","        if(s->T1[i] != -1) {\n","            printf(\"%d \", i);\n","        }\n","        // printf(\"%d \", s->T1[i]);\n","    }\n","\n","    printf(\"\\nT2\\n\");\n","    for (int i = 0; i < numVertices; i++) {\n","        if(s->T2[i] != -1) {\n","            printf(\"%d \", i);\n","        }\n","        // printf(\"%d \", s->T2[i]);\n","    }\n","\n","    printf(\"\\nT1_out\\n\");\n","    for (int i = 0; i < numVertices; i++) {\n","        if(s->T1_out[i] != -1) {\n","            printf(\"%d \", i);\n","        }\n","        // printf(\"%d \", s->T1_out[i]);\n","    }\n","\n","    printf(\"\\nT2_out\\n\");\n","    for (int i = 0; i < numVertices; i++) {\n","        if(s->T2_out[i] != -1) {\n","            printf(\"%d \", i);\n","        }\n","        // printf(\"%d \", s->T2_out[i]);\n","    }\n","}\n","\n","bool isMappingFull(Graph* g, State* state) {\n","    for(int i = 0; i < g->numVertices; i++) {\n","        if(state->mapping1[i] == -1) {\n","            return false;\n","        }\n","    }\n","    return true;\n","}\n","\n","__global__ void updateStateKernel(int* matrix, int V, int* mapping, int* T, int* T_out, int node) {\n","    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n","\n","    if( idx < V) {\n","        if(matrix[node * V + idx] == 1 && mapping[idx] == -1) {\n","            T[idx] = 1;\n","            T_out[idx] = -1;\n","        }\n","    }\n","\n","}\n","\n","void updateState(Graph* g1, Graph* g2, State* state, int node, int candidate) {\n","    int* d_matrix1, *d_matrix2;\n","    int* d_mapping1, *d_mapping2;\n","    int* d_T1, *d_T1_out;\n","    int* d_T2, *d_T2_out;\n","\n","    cudaStream_t stream1, stream2;\n","    cudaStreamCreate(&stream1);\n","    cudaStreamCreate(&stream2);\n","\n","    CUDA_CHECK_ERROR(cudaMalloc((void**)&d_matrix1, g1->numVertices * g1->numVertices * sizeof(int)));\n","    CUDA_CHECK_ERROR(cudaMalloc((void**)&d_mapping1, g1->numVertices * sizeof(int)));\n","    CUDA_CHECK_ERROR(cudaMalloc((void**)&d_T1, g1->numVertices * sizeof(int)));\n","    CUDA_CHECK_ERROR(cudaMalloc((void**)&d_T1_out, g1->numVertices * sizeof(int)));\n","\n","    CUDA_CHECK_ERROR(cudaMemcpyAsync(d_matrix1, g1->matrix, g1->numVertices * g1->numVertices * sizeof(int), cudaMemcpyHostToDevice, stream1));\n","    CUDA_CHECK_ERROR(cudaMemcpyAsync(d_mapping1, state->mapping1, g1->numVertices * sizeof(int), cudaMemcpyHostToDevice, stream1));\n","    CUDA_CHECK_ERROR(cudaMemcpyAsync(d_T1, state->T1, g1->numVertices * sizeof(int), cudaMemcpyHostToDevice, stream1));\n","    CUDA_CHECK_ERROR(cudaMemcpyAsync(d_T1_out, state->T1_out, g1->numVertices * sizeof(int), cudaMemcpyHostToDevice, stream1));\n","\n","    int gridSize = (g1->numVertices + blockSize - 1) / blockSize;\n","\n","    updateStateKernel<<<gridSize, blockSize, 0, stream1>>>(d_matrix1, g1->numVertices, d_mapping1, d_T1, d_T1_out, node);\n","\n","    CUDA_CHECK_ERROR(cudaMalloc((void**)&d_matrix2, g2->numVertices * g2->numVertices * sizeof(int)));\n","    CUDA_CHECK_ERROR(cudaMalloc((void**)&d_mapping2, g2->numVertices * sizeof(int)));\n","    CUDA_CHECK_ERROR(cudaMalloc((void**)&d_T2, g2->numVertices * sizeof(int)));\n","    CUDA_CHECK_ERROR(cudaMalloc((void**)&d_T2_out, g2->numVertices * sizeof(int)));\n","\n","    CUDA_CHECK_ERROR(cudaMemcpyAsync(d_matrix2, g2->matrix, g2->numVertices * g2->numVertices * sizeof(int), cudaMemcpyHostToDevice, stream2));\n","    CUDA_CHECK_ERROR(cudaMemcpyAsync(d_mapping2, state->mapping2, g2->numVertices * sizeof(int), cudaMemcpyHostToDevice, stream2));\n","    CUDA_CHECK_ERROR(cudaMemcpyAsync(d_T2, state->T2, g2->numVertices * sizeof(int), cudaMemcpyHostToDevice, stream2));\n","    CUDA_CHECK_ERROR(cudaMemcpyAsync(d_T2_out, state->T2_out, g2->numVertices * sizeof(int), cudaMemcpyHostToDevice, stream2));\n","\n","    gridSize = (g2->numVertices + blockSize - 1) / blockSize;\n","\n","    updateStateKernel<<<gridSize, blockSize, 0, stream2>>>(d_matrix2, g2->numVertices, d_mapping2, d_T2, d_T2_out, candidate);\n","\n","    cudaStreamSynchronize(stream1);\n","\n","    CUDA_CHECK_ERROR(cudaMemcpy(state->T1, d_T1, g1->numVertices * sizeof(int), cudaMemcpyDeviceToHost));\n","    CUDA_CHECK_ERROR(cudaMemcpy(state->T1_out, d_T1_out, g1->numVertices * sizeof(int), cudaMemcpyDeviceToHost));\n","\n","    cudaStreamDestroy(stream1);\n","    cudaFree(d_matrix1);\n","    cudaFree(d_mapping1);\n","    cudaFree(d_T1);\n","    cudaFree(d_T1_out);\n","\n","    state->T1[node] = -1;\n","    state->T1_out[node] = -1;\n","\n","    cudaStreamSynchronize(stream2);\n","\n","    CUDA_CHECK_ERROR(cudaMemcpy(state->T2, d_T2, g2->numVertices * sizeof(int), cudaMemcpyDeviceToHost));\n","    CUDA_CHECK_ERROR(cudaMemcpy(state->T2_out, d_T2_out, g2->numVertices * sizeof(int), cudaMemcpyDeviceToHost));\n","\n","    cudaStreamDestroy(stream2);\n","    cudaFree(d_matrix2);\n","    cudaFree(d_mapping2);\n","    cudaFree(d_T2);\n","    cudaFree(d_T2_out);\n","\n","    state->T2[candidate] = -1;\n","    state->T2_out[candidate] = -1;\n","}\n","\n","__global__ void restoreStateKernel(int* matrix, int V, int node, int* T, int* T_out, int* mapping) {\n","    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n","\n","    if (idx >= V) {\n","        return;\n","    }\n","\n","    int isAdded = 0;\n","\n","    if(matrix[node * V + idx] == 1) {\n","\n","        if(mapping[idx] != -1) {\n","            atomicExch(&T[node], 1);\n","            isAdded = 1;\n","        }\n","        else {\n","            int hasCoveredNeighbor = 0;\n","            for(int adjVertex2 = 0; adjVertex2 < V; adjVertex2++) {\n","                if(matrix[idx * V + adjVertex2] == 1 && mapping[adjVertex2] != -1) {\n","                    hasCoveredNeighbor = 1;\n","                    break;\n","                }\n","            }\n","\n","            if(hasCoveredNeighbor == 0) {\n","                T[idx] = -1;\n","                T_out[idx] = 1;\n","            }\n","        }\n","    }\n","\n","    if(isAdded == 0) {\n","        atomicExch(&T_out[node], 1);\n","    }\n","}\n","\n","void restoreState(Graph* g1, Graph* g2, State* state, int node, int candidate) {\n","    int* d_matrix1, *d_matrix2;\n","    int* d_mapping1, *d_mapping2;\n","    int* d_T1, *d_T1_out;\n","    int* d_T2, *d_T2_out;\n","\n","    cudaStream_t stream1, stream2;\n","    cudaStreamCreate(&stream1);\n","    cudaStreamCreate(&stream2);\n","\n","    CUDA_CHECK_ERROR(cudaMalloc((void**)&d_matrix1, g1->numVertices * g1->numVertices * sizeof(int)));\n","    CUDA_CHECK_ERROR(cudaMalloc((void**)&d_mapping1, g1->numVertices * sizeof(int)));\n","    CUDA_CHECK_ERROR(cudaMalloc((void**)&d_T1, g1->numVertices * sizeof(int)));\n","    CUDA_CHECK_ERROR(cudaMalloc((void**)&d_T1_out, g1->numVertices * sizeof(int)));\n","\n","    CUDA_CHECK_ERROR(cudaMemcpyAsync(d_matrix1, g1->matrix, g1->numVertices * g1->numVertices * sizeof(int), cudaMemcpyHostToDevice, stream1));\n","    CUDA_CHECK_ERROR(cudaMemcpyAsync(d_mapping1, state->mapping1, g1->numVertices * sizeof(int), cudaMemcpyHostToDevice, stream1));\n","    CUDA_CHECK_ERROR(cudaMemcpyAsync(d_T1, state->T1, g1->numVertices * sizeof(int), cudaMemcpyHostToDevice, stream1));\n","    CUDA_CHECK_ERROR(cudaMemcpyAsync(d_T1_out, state->T1_out, g1->numVertices * sizeof(int), cudaMemcpyHostToDevice, stream1));\n","\n","    int gridSize = (g1->numVertices + blockSize - 1) / blockSize;\n","\n","    restoreStateKernel<<<gridSize, blockSize, 0, stream1>>>(d_matrix1, g1->numVertices, node, d_T1, d_T1_out, d_mapping1);\n","\n","    CUDA_CHECK_ERROR(cudaMalloc((void**)&d_matrix2, g2->numVertices * g2->numVertices * sizeof(int)));\n","    CUDA_CHECK_ERROR(cudaMalloc((void**)&d_mapping2, g2->numVertices * sizeof(int)));\n","    CUDA_CHECK_ERROR(cudaMalloc((void**)&d_T2, g2->numVertices * sizeof(int)));\n","    CUDA_CHECK_ERROR(cudaMalloc((void**)&d_T2_out, g2->numVertices * sizeof(int)));\n","\n","    CUDA_CHECK_ERROR(cudaMemcpyAsync(d_matrix2, g2->matrix, g2->numVertices * g2->numVertices * sizeof(int), cudaMemcpyHostToDevice, stream2));\n","    CUDA_CHECK_ERROR(cudaMemcpyAsync(d_mapping2, state->mapping2, g2->numVertices * sizeof(int), cudaMemcpyHostToDevice, stream2));\n","    CUDA_CHECK_ERROR(cudaMemcpyAsync(d_T2, state->T2, g2->numVertices * sizeof(int), cudaMemcpyHostToDevice, stream2));\n","    CUDA_CHECK_ERROR(cudaMemcpyAsync(d_T2_out, state->T2_out, g2->numVertices * sizeof(int), cudaMemcpyHostToDevice, stream2));\n","\n","    gridSize = (g2->numVertices + blockSize - 1) / blockSize;\n","\n","    restoreStateKernel<<<gridSize, blockSize, 0, stream2>>>(d_matrix2, g2->numVertices, candidate, d_T2, d_T2_out, d_mapping2);\n","\n","    cudaStreamSynchronize(stream1);\n","\n","    CUDA_CHECK_ERROR(cudaMemcpy(state->T1, d_T1, g1->numVertices * sizeof(int), cudaMemcpyDeviceToHost));\n","    CUDA_CHECK_ERROR(cudaMemcpy(state->T1_out, d_T1_out, g1->numVertices * sizeof(int), cudaMemcpyDeviceToHost));\n","\n","    cudaStreamDestroy(stream1);\n","    cudaFree(d_matrix1);\n","    cudaFree(d_mapping1);\n","    cudaFree(d_T1);\n","    cudaFree(d_T1_out);\n","\n","    cudaStreamSynchronize(stream2);\n","\n","    CUDA_CHECK_ERROR(cudaMemcpy(state->T2, d_T2, g2->numVertices * sizeof(int), cudaMemcpyDeviceToHost));\n","    CUDA_CHECK_ERROR(cudaMemcpy(state->T2_out, d_T2_out, g2->numVertices * sizeof(int), cudaMemcpyDeviceToHost));\n","\n","    cudaStreamDestroy(stream2);\n","    cudaFree(d_matrix2);\n","    cudaFree(d_mapping2);\n","    cudaFree(d_T2);\n","    cudaFree(d_T2_out);\n","}\n","\n","/***** VF2++ FUNCTIONS *****/\n","bool checkGraphProperties(Graph* g1, Graph* g2) {\n","    if (g1->numVertices != g2->numVertices || g1->numVertices == 0 || g2->numVertices == 0) {\n","        return false;\n","    }\n","\n","    if (!checkSequenceDegree(g1->degrees, g2->degrees, g1->numVertices)) {\n","        return false;\n","    }\n","\n","    for(int i = 0; i < LABELS; i++) {\n","        if (g1->labelsCardinalities[i] != g2->labelsCardinalities[i]) {\n","            return false;\n","        }\n","    }\n","\n","    return true;\n","}\n","\n","__global__ void checkSequenceDegreeKernel(int* arr1, int* arr2, int size, int* ret) {\n","    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n","\n","    if (idx < size) {\n","        if (arr1[idx] != arr2[idx]) {\n","            *ret = 0;\n","        }\n","    }\n","}\n","\n","bool checkSequenceDegree(int* degree1, int* degree2, int size) {\n","    int* tmp1 = (int*)malloc(size * sizeof(int));\n","    int* tmp2 = (int*)malloc(size * sizeof(int));\n","\n","    memcpy(tmp1, degree1, size * sizeof(int));\n","    memcpy(tmp2, degree2, size * sizeof(int));\n","\n","    qsort(tmp1, size, sizeof(int), compare);\n","    qsort(tmp2, size, sizeof(int), compare);\n","\n","    int* d_tmp1, *d_tmp2, *d_ret;\n","    int h_ret = 1;\n","\n","    CUDA_CHECK_ERROR(cudaMalloc((void**)&d_tmp1, size * sizeof(int)));\n","    CUDA_CHECK_ERROR(cudaMalloc((void**)&d_tmp2, size * sizeof(int)));\n","    CUDA_CHECK_ERROR(cudaMalloc((void**)&d_ret, sizeof(int)));\n","\n","    CUDA_CHECK_ERROR(cudaMemcpy(d_tmp1, tmp1, size * sizeof(int), cudaMemcpyHostToDevice));\n","    CUDA_CHECK_ERROR(cudaMemcpy(d_tmp2, tmp2, size * sizeof(int), cudaMemcpyHostToDevice));\n","    CUDA_CHECK_ERROR(cudaMemcpy(d_ret, &h_ret, sizeof(int), cudaMemcpyHostToDevice));\n","\n","    int gridSize = (size + blockSize - 1) / blockSize;\n","    checkSequenceDegreeKernel<<<blockSize, gridSize>>>(d_tmp1, d_tmp2, size, &d_ret);\n","\n","    cudaDeviceSynchronize();\n","\n","    CUDA_CHECK_ERROR(cudaMemcpy(&h_ret, d_ret, sizeof(int), cudaMemcpyDeviceToHost));\n","\n","    cudaFree(d_tmp1);\n","    cudaFree(d_tmp2);\n","    cudaFree(d_ret);\n","\n","    free(tmp1);\n","    free(tmp2);\n","    return h_ret;\n","}\n","\n","int compare(const void* a, const void* b) {\n","    return (*(int*)a - *(int*)b);\n","}\n","\n","__global__ void bfsKernel(int* matrix, int V, int* levels, int* d_done, int depth) {\n","    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n","    __shared__ int s_done;\n","    extern __shared__ int s_levels[];\n","\n","    if(threadIdx.x == 0) {\n","        s_done = 0;\n","    }\n","\n","    // it copies the whole levels array in shared memory\n","    // example: thread 0 loads levels[0] and levels[4] if blockSize is 4\n","    for(int i = threadIdx.x; i < V; i += blockDim.x) {\n","      s_levels[i] = levels[i];\n","    }\n","\n","    __syncthreads();\n","\n","    // levels is used as visited too\n","    if(idx < V && s_levels[idx] == depth) {    // it blocks all thread with size greater than V and all threads not at the current depth\n","\n","        for(int adjVertex = 0; adjVertex < V; adjVertex++) {\n","            if(matrix[idx * V + adjVertex] == 1 && s_levels[adjVertex] == -1) {\n","                atomicExch(&levels[adjVertex], depth + 1);\n","                s_done = 1;\n","            }\n","        }\n","    }\n","\n","    __syncthreads();\n","\n","    if(threadIdx.x == 0) {\n","        atomicExch(d_done, s_done);\n","    }\n","}\n","\n","__global__ void maxRarityKernel(int V, int* d_labelRarity, int* d_nodesToLabel, int* d_maxRarity, int* d_is_good) {\n","    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n","    extern __shared__ int s_data[];\n","\n","    if(idx < V && d_is_good[idx]) {\n","        s_data[threadIdx.x] = d_labelRarity[d_nodesToLabel[idx]];\n","    } else {\n","        s_data[threadIdx.x] = INF;\n","    }\n","\n","    __syncthreads();\n","\n","    // parallel reduction: at each step, the block is halved and each thread computes the min of its value with the value of the other one at distance s in\n","    // the same block\n","    for(unsigned int s = blockDim.x / 2; s > 0; s >>= 1) {\n","        if(threadIdx.x < s) {\n","            s_data[threadIdx.x] = min(s_data[threadIdx.x], s_data[threadIdx.x + s]);   // At the end of the loop, the min value is in sdata[0]\n","        }\n","        __syncthreads();\n","    }\n","\n","    // each thread 0 of each block computes the global min\n","    if(threadIdx.x == 0) {\n","        atomicMin(d_maxRarity, s_data[0]);\n","    }\n","}\n","\n","__global__ void maxRarityFilterKernel(int V, int* d_labelRarity, int* d_nodesToLabel, int* d_maxRarity, int* d_is_good) {\n","    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n","\n","    if(idx < V) {\n","        if(d_labelRarity[d_nodesToLabel[idx]] != *d_maxRarity) {\n","            d_is_good[idx] = 0;\n","        }\n","    }\n","}\n","\n","__global__ void maxDegreeKernel(int V, int* d_degrees, int* d_maxDegree, int* d_is_good) {\n","    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n","    extern __shared__ int s_data[];\n","\n","    if(idx < V && d_is_good[idx]) {\n","        s_data[threadIdx.x] = d_degrees[idx];\n","    }\n","    else {\n","        s_data[threadIdx.x] = -INF;\n","    }\n","\n","    __syncthreads();\n","\n","    for(unsigned int s = blockDim.x / 2; s > 0; s >>= 1) {\n","        if(threadIdx.x < s) {\n","            s_data[threadIdx.x] = max(s_data[threadIdx.x], s_data[threadIdx.x + s]);\n","        }\n","        __syncthreads();\n","    }\n","\n","    if(threadIdx.x == 0) {\n","        atomicMax(d_maxDegree, s_data[0]);\n","    }\n","}\n","\n","__global__ void maxDegreeFilterKernel(int V, int* d_degrees, int* d_maxDegree, int* d_is_good) {\n","    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n","\n","    if(idx < V) {\n","        if(d_degrees[idx] != *d_maxDegree) {\n","            d_is_good[idx] = 0;\n","        }\n","    }\n","}\n","\n","__global__ void findNodeKernel(int V, int* is_good, int* d_node) {\n","    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n","    if(idx < V && is_good[idx]) {\n","        atomicExch(d_node, idx);\n","    }\n","}\n","\n","__global__ void initArrayKernel(int* d_array, int size, int value) {\n","    int idx = threadIdx.x + blockIdx.x * blockDim.x;\n","    if (idx < size) {\n","        d_array[idx] = value;\n","    }\n","}\n","\n","int findRoot(int V, int* d_labelRarity, int* d_nodesToLabel, int* d_degrees) {\n","    int* d_root, *d_is_good, *d_maxRarity, *d_maxDegree;\n","    int h_root = -1, h_maxRarity = INF, h_maxDegree = -INF;\n","\n","    int gridSize = (V + blockSize - 1) / blockSize;\n","\n","    CUDA_CHECK_ERROR(cudaMalloc((void**)&d_root, sizeof(int)));\n","    CUDA_CHECK_ERROR(cudaMalloc((void**)&d_is_good, V * sizeof(int)));\n","    CUDA_CHECK_ERROR(cudaMalloc((void**)&d_maxRarity, sizeof(int)));\n","    CUDA_CHECK_ERROR(cudaMalloc((void**)&d_maxDegree, sizeof(int)));\n","\n","    initArrayKernel<<<gridSize, blockSize>>>(d_is_good, V, 1);\n","    CUDA_CHECK_ERROR(cudaMemcpy(d_maxRarity, &h_maxRarity, sizeof(int), cudaMemcpyHostToDevice));\n","    CUDA_CHECK_ERROR(cudaMemcpy(d_maxDegree, &h_maxDegree, sizeof(int), cudaMemcpyHostToDevice));\n","    cudaDeviceSynchronize();\n","\n","    size_t sharedMemSize = blockSize * sizeof(int); // each block has a shared memory of size blockSize\n","\n","    maxRarityKernel<<<gridSize, blockSize, sharedMemSize>>>(V, d_labelRarity, d_nodesToLabel, d_maxRarity, d_is_good);\n","    cudaDeviceSynchronize();\n","    maxRarityFilterKernel<<<gridSize, blockSize>>>(V, d_labelRarity, d_nodesToLabel, d_maxRarity, d_is_good);\n","    cudaDeviceSynchronize();\n","    maxDegreeKernel<<<gridSize, blockSize, sharedMemSize>>>(V, d_degrees, d_maxDegree, d_is_good);\n","    cudaDeviceSynchronize();\n","    maxDegreeFilterKernel<<<gridSize, blockSize>>>(V, d_degrees, d_maxDegree, d_is_good);\n","    cudaDeviceSynchronize();\n","    findNodeKernel<<<gridSize, blockSize>>>(V, d_is_good, d_root);\n","    cudaDeviceSynchronize();\n","\n","    CUDA_CHECK_ERROR(cudaMemcpy(&h_root, d_root, sizeof(int), cudaMemcpyDeviceToHost));\n","\n","    cudaFree(d_maxDegree);\n","    cudaFree(d_is_good);\n","    cudaFree(d_maxRarity);\n","    cudaFree(d_root);\n","    return h_root;\n","}\n","\n","__global__ void findLevelNodesKernel(int* levels, int depth, int* levelNodes, int V, int* levelSize) {\n","    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n","\n","    __shared__ int s_levelSize;\n","\n","    if(threadIdx.x == 0) {\n","        s_levelSize = 0;\n","    }\n","\n","    __syncthreads();\n","\n","    if(idx < V && levels[idx] == depth) {\n","        atomicAdd(&s_levelSize, 1);\n","        levelNodes[idx] = 1;\n","    }\n","\n","    __syncthreads();\n","\n","    if(threadIdx.x == 0) {\n","        atomicAdd(levelSize, s_levelSize);\n","    }\n","}\n","\n","int* ordering(Graph* g1, Graph* g2) {\n","    int* d_g1_matrix, *d_g1_nodesToLabel, *d_g1_degrees, *d_V1Unordered, *d_labelRarity, *d_connectivityG1;\n","\n","    CUDA_CHECK_ERROR(cudaMalloc((void**)&d_g1_matrix, g1->numVertices * g1->numVertices * sizeof(int)));\n","    CUDA_CHECK_ERROR(cudaMalloc((void**)&d_g1_nodesToLabel, g1->numVertices * sizeof(int)));\n","    CUDA_CHECK_ERROR(cudaMalloc((void**)&d_g1_degrees, g1->numVertices * sizeof(int)));\n","    CUDA_CHECK_ERROR(cudaMalloc((void**)&d_V1Unordered, g1->numVertices * sizeof(int)));\n","    CUDA_CHECK_ERROR(cudaMalloc((void**)&d_labelRarity, LABELS * sizeof(int)));\n","    CUDA_CHECK_ERROR(cudaMalloc((void**)&d_connectivityG1, g1->numVertices * sizeof(int)));\n","\n","    CUDA_CHECK_ERROR(cudaMemcpy(d_g1_matrix, g1->matrix, g1->numVertices * g1->numVertices * sizeof(int), cudaMemcpyHostToDevice));\n","    CUDA_CHECK_ERROR(cudaMemcpy(d_g1_nodesToLabel, g1->nodesToLabel, g1->numVertices * sizeof(int), cudaMemcpyHostToDevice));\n","    CUDA_CHECK_ERROR(cudaMemcpy(d_g1_degrees, g1->degrees, g1->numVertices * sizeof(int), cudaMemcpyHostToDevice));\n","    CUDA_CHECK_ERROR(cudaMemcpy(d_labelRarity, g1->labelsCardinalities, LABELS * sizeof(int), cudaMemcpyHostToDevice));\n","    CUDA_CHECK_ERROR(cudaMemset(d_V1Unordered, -1, g1->numVertices * sizeof(int)));\n","    CUDA_CHECK_ERROR(cudaMemset(d_connectivityG1, 0, g1->numVertices * sizeof(int)));\n","\n","    int root = findRoot(g1->numVertices, d_labelRarity, d_g1_nodesToLabel, d_g1_degrees);\n","\n","    int* levels = (int*)malloc(g1->numVertices * sizeof(int));\n","    int* order = (int*)malloc(g1->numVertices * sizeof(int));   // order of the nodes of g1\n","    int order_index = 0;\n","\n","    if (order == NULL || levels == NULL) {\n","        printf(\"Error allocating memory in ordering\\n\");\n","        exit(EXIT_FAILURE);\n","    }\n","\n","    for(int i = 0; i < g1->numVertices; i++) {\n","        levels[i] = -1;\n","    }\n","\n","    int* d_levels, *d_done, *d_levelNodes, *d_levelSize;\n","    int depth = 0;\n","    int h_done;\n","\n","    CUDA_CHECK_ERROR(cudaMalloc((void**)&d_levels, g1->numVertices * sizeof(int)));\n","    CUDA_CHECK_ERROR(cudaMalloc((void**)&d_done, sizeof(int)));\n","\n","    levels[root] = depth;\n","\n","    CUDA_CHECK_ERROR(cudaMemcpy(d_levels, levels, g1->numVertices * sizeof(int), cudaMemcpyHostToDevice));\n","\n","    int gridSize = (g1->numVertices + blockSize - 1) / blockSize;\n","    size_t sharedMemSize = sizeof(int) * g1->numVertices;\n","\n","    do {\n","        h_done = 0;\n","        CUDA_CHECK_ERROR(cudaMemcpy(d_done, &h_done, sizeof(int), cudaMemcpyHostToDevice));\n","\n","        bfsKernel<<<gridSize, blockSize, sharedMemSize>>>(d_g1_matrix, g1->numVertices, d_levels, d_done, depth);\n","        cudaDeviceSynchronize();\n","\n","        CUDA_CHECK_ERROR(cudaMemcpy(&h_done, d_done, sizeof(int), cudaMemcpyDeviceToHost));\n","        depth++;\n","    } while(h_done);\n","\n","    CUDA_CHECK_ERROR(cudaMemcpy(levels, d_levels, g1->numVertices*sizeof(int), cudaMemcpyDeviceToHost));\n","\n","    CUDA_CHECK_ERROR(cudaMalloc((void**)&d_levelNodes, g1->numVertices * sizeof(int)));\n","    CUDA_CHECK_ERROR(cudaMalloc((void**)&d_levelSize, sizeof(int)));\n","\n","    gridSize = (g1->numVertices + blockSize - 1) / blockSize;\n","    for (int d = 0; d < depth; d++) {\n","        CUDA_CHECK_ERROR(cudaMemset(d_levelNodes, 0, g1->numVertices * sizeof(int)));\n","        CUDA_CHECK_ERROR(cudaMemset(d_levelSize, 0, sizeof(int)));\n","\n","        findLevelNodesKernel<<<gridSize, blockSize, 0>>>(d_levels, d, d_levelNodes, g1->numVertices, d_levelSize);\n","        cudaDeviceSynchronize();\n","        processDepth(order, &order_index, d_connectivityG1, d_labelRarity, d_V1Unordered, d_levelNodes,\n","                    g1->numVertices, d_g1_degrees, d_g1_nodesToLabel, d_g1_matrix, d_levelSize);\n","    }\n","\n","    free(levels);\n","\n","    cudaFree(d_g1_matrix);\n","    cudaFree(d_g1_nodesToLabel);\n","    cudaFree(d_g1_degrees);\n","    cudaFree(d_V1Unordered);\n","    cudaFree(d_labelRarity);\n","    cudaFree(d_connectivityG1);\n","    cudaFree(d_levels);\n","    cudaFree(d_done);\n","    cudaFree(d_levelNodes);\n","    cudaFree(d_levelSize);\n","\n","    return order;\n","}\n","\n","__global__ void maxConnectivityKernel(int* d_connectivityG1, int* d_maxConnectivity, int* d_is_good, int V) {\n","    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n","    extern __shared__ int s_data[];\n","\n","    if(idx < V && d_is_good[idx]) { // d_is_good already contains the information about the nodes of the current level\n","        int conn = d_connectivityG1[idx];\n","        s_data[threadIdx.x] = conn;\n","    } else {\n","        s_data[threadIdx.x] = -INF;\n","    }\n","\n","    __syncthreads();\n","\n","    for(unsigned int s = blockDim.x / 2; s > 0; s >>= 1) {\n","        if(threadIdx.x < s) {\n","            s_data[threadIdx.x] = max(s_data[threadIdx.x], s_data[threadIdx.x + s]);\n","        }\n","        __syncthreads();\n","    }\n","\n","    if(threadIdx.x == 0) {\n","        atomicMax(d_maxConnectivity, s_data[0]);\n","    }\n","}\n","\n","__global__ void maxConnectivityFilterKernel(int* d_connectivityG1, int* d_maxConnectivity, int* d_is_good, int V) {\n","    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n","\n","    if(idx < V) {\n","        if(d_connectivityG1[idx] != *d_maxConnectivity) {\n","            d_is_good[idx] = 0;\n","        }\n","    }\n","}\n","\n","__global__ void unorderedFilterKernel(int* d_is_good, int* d_V1Unordered, int* d_levelNodes, int V) {\n","    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n","\n","    if(idx >= V) {\n","        return;\n","    }\n","\n","    if(d_levelNodes[idx]) {\n","        if(d_V1Unordered[idx] == 1) {\n","            d_is_good[idx] = 0;\n","        }\n","    } else {\n","        d_is_good[idx] = 0;\n","    }\n","}\n","\n","__global__ void updateConnKernel(int* matrix, int V, int* connectivity, int node) {\n","    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n","\n","    if(idx < V) {\n","        if(matrix[node * V + idx] == 1) {\n","            atomicAdd(&connectivity[idx], 1);\n","        }\n","    }\n","}\n","\n","void processDepth(int* order, int* order_index, int* d_connectivityG1, int* d_labelRarity, int* d_V1Unordered, int* d_levelNodes, int V,\n","                    int* d_degrees, int* d_nodesToLabel, int* d_matrix, int* d_levelSize) {\n","\n","    int* d_is_good, *d_maxDegree, *d_maxRarity, *d_maxConnectivity, *d_nextNode;\n","    int h_nextNode, h_levelSize, h_maxRarity = INF, h_maxConnectivity = -INF, h_maxDegree = -INF;\n","    int* h_labelRarity = (int*)malloc(LABELS * sizeof(int));\n","    int* h_nodesToLabel = (int*)malloc(V * sizeof(int));\n","    int *h_V1Unordered = (int*)malloc(V * sizeof(int));\n","\n","    CUDA_CHECK_ERROR(cudaMemcpy(&h_levelSize, d_levelSize, sizeof(int), cudaMemcpyDeviceToHost));\n","\n","    CUDA_CHECK_ERROR(cudaMalloc((void**)&d_is_good, V * sizeof(int)));\n","    CUDA_CHECK_ERROR(cudaMalloc((void**)&d_maxDegree, sizeof(int)));\n","    CUDA_CHECK_ERROR(cudaMalloc((void**)&d_maxRarity, sizeof(int)));\n","    CUDA_CHECK_ERROR(cudaMalloc((void**)&d_maxConnectivity, sizeof(int)));\n","    CUDA_CHECK_ERROR(cudaMalloc((void**)&d_nextNode, sizeof(int)));\n","\n","    int gridSize = (V + blockSize - 1) / blockSize;\n","    size_t sharedMemSize = blockSize * sizeof(int);\n","\n","    cudaStream_t stream;\n","    cudaStreamCreate(&stream);\n","\n","    while(h_levelSize > 0) {\n","        initArrayKernel<<<gridSize, blockSize>>>(d_is_good, V, 1);\n","        cudaDeviceSynchronize();\n","\n","        CUDA_CHECK_ERROR(cudaMemcpy(d_maxRarity, &h_maxRarity, sizeof(int), cudaMemcpyHostToDevice));\n","        CUDA_CHECK_ERROR(cudaMemcpy(d_maxDegree, &h_maxDegree, sizeof(int), cudaMemcpyHostToDevice));\n","        CUDA_CHECK_ERROR(cudaMemcpy(d_maxConnectivity, &h_maxConnectivity, sizeof(int), cudaMemcpyHostToDevice));\n","\n","        unorderedFilterKernel<<<gridSize, blockSize>>>(d_is_good, d_V1Unordered, d_levelNodes, V);\n","        cudaDeviceSynchronize();\n","        maxConnectivityKernel<<<gridSize, blockSize, sharedMemSize>>>(d_connectivityG1, d_maxConnectivity, d_is_good, V);\n","        cudaDeviceSynchronize();\n","        maxConnectivityFilterKernel<<<gridSize, blockSize>>>(d_connectivityG1, d_maxConnectivity, d_is_good, V);\n","        cudaDeviceSynchronize();\n","        maxDegreeKernel<<<gridSize, blockSize, sharedMemSize>>>(V, d_degrees, d_maxDegree, d_is_good);\n","        cudaDeviceSynchronize();\n","        maxDegreeFilterKernel<<<gridSize, blockSize>>>(V, d_degrees, d_maxDegree, d_is_good);\n","        cudaDeviceSynchronize();\n","        maxRarityKernel<<<gridSize, blockSize, sharedMemSize>>>(V, d_labelRarity, d_nodesToLabel, d_maxRarity, d_is_good);\n","        cudaDeviceSynchronize();\n","        maxRarityFilterKernel<<<gridSize, blockSize>>>(V, d_labelRarity, d_nodesToLabel, d_maxRarity, d_is_good);\n","        cudaDeviceSynchronize();\n","        findNodeKernel<<<gridSize, blockSize>>>(V, d_is_good, d_nextNode);\n","        cudaDeviceSynchronize();\n","\n","        CUDA_CHECK_ERROR(cudaMemcpy(&h_nextNode, d_nextNode, sizeof(int), cudaMemcpyDeviceToHost));\n","\n","        updateConnKernel<<<gridSize, blockSize, 0, stream>>>(d_matrix, V, d_connectivityG1, h_nextNode);\n","\n","        order[(*order_index)++] = h_nextNode;\n","        h_levelSize--;\n","\n","        CUDA_CHECK_ERROR(cudaMemcpy(h_labelRarity, d_labelRarity, LABELS * sizeof(int), cudaMemcpyDeviceToHost));\n","        CUDA_CHECK_ERROR(cudaMemcpy(h_nodesToLabel, d_nodesToLabel, V * sizeof(int), cudaMemcpyDeviceToHost));\n","        CUDA_CHECK_ERROR(cudaMemcpy(h_V1Unordered, d_V1Unordered, V * sizeof(int), cudaMemcpyDeviceToHost));\n","\n","        h_labelRarity[h_nodesToLabel[h_nextNode]]--;\n","        h_V1Unordered[h_nextNode] = 1;\n","\n","        CUDA_CHECK_ERROR(cudaMemcpy(d_labelRarity, h_labelRarity, LABELS * sizeof(int), cudaMemcpyHostToDevice));\n","        CUDA_CHECK_ERROR(cudaMemcpy(d_nodesToLabel, h_nodesToLabel, V * sizeof(int), cudaMemcpyHostToDevice));\n","        CUDA_CHECK_ERROR(cudaMemcpy(d_V1Unordered, h_V1Unordered, V * sizeof(int), cudaMemcpyHostToDevice));\n","\n","        cudaStreamSynchronize(stream);\n","    }\n","\n","    cudaStreamDestroy(stream);\n","    cudaFree(d_maxDegree);\n","    cudaFree(d_maxRarity);\n","    cudaFree(d_maxConnectivity);\n","    cudaFree(d_nextNode);\n","    cudaFree(d_is_good);\n","}\n","\n","__global__ void findCoveredNeighborsKernel(int* matrix1, int* mapping1, int node, int* coveredNeighbors, int* coveredNeighborsSize,\n","                                            int numVertices) {\n","\n","    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n","\n","    if(idx >= numVertices)\n","        return;\n","\n","    if(matrix1[node * numVertices + idx] == 1 && mapping1[idx] != -1) {\n","        int index = atomicAdd(coveredNeighborsSize, 1);\n","        coveredNeighbors[index] = idx;\n","    }\n","}\n","\n","__global__ void findCandidatesKernel(int* coveredNeighborsSize, int g1_label, int maxSizeCandidates,\n","                                    int* g2_vertexList, int g1_degree, int* g2_degrees, int* T2_out, int* mapping2, int* candidates, int* candidateSize,\n","                                    int g2_numVertices, int* commonNodes, int* coveredNeighbors, int* g2_matrix, int* mapping1, int* g2_nodesToLabel) {\n","\n","    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n","\n","    if(*coveredNeighborsSize == 0) {\n","\n","        if(idx < maxSizeCandidates) {\n","            int vertex = g2_vertexList[idx];  // g2_labelToNodes[label]\n","            if(g2_degrees[vertex] == g1_degree && T2_out[vertex] == 1 && mapping2[vertex] != 1) {\n","                int index = atomicAdd(candidateSize, 1);\n","                candidates[index] = vertex;\n","            }\n","        }\n","    }\n","    else {\n","\n","        if(idx < g2_numVertices) {\n","           commonNodes[idx] = 1;\n","\n","            for (int i = 0; i < *coveredNeighborsSize; i++) {\n","                int nbrG1 = coveredNeighbors[i];\n","                int mappedG2 = mapping1[nbrG1];\n","                if (g2_matrix[mappedG2 * g2_numVertices + idx] == 0) {\n","                    commonNodes[idx] = 0;\n","                }\n","            }\n","\n","            if (commonNodes[idx] && mapping2[idx] == 1) {\n","                commonNodes[idx] = 0;\n","            }\n","\n","            if (commonNodes[idx] && g2_degrees[idx] != g1_degree) {\n","                commonNodes[idx] = 0;\n","            }\n","\n","            if (commonNodes[idx] && g2_nodesToLabel[idx] != g1_label) {\n","                commonNodes[idx] = 0;\n","            }\n","\n","            if (commonNodes[idx] == 1) {\n","                int index = atomicAdd(candidateSize, 1);\n","                candidates[index] = idx;\n","            }\n","        }\n","    }\n","}\n","\n","int* findCandidates(Graph* g1, Graph* g2, State* state, int node, int* sizeCandidates) {\n","    // output\n","    int* d_coveredNeighbors, *d_coveredNeighborsSize;\n","    int coveredNeighborsSize = 0;\n","\n","    // input\n","    int* d_matrix1, *d_mapping1;\n","\n","    CUDA_CHECK_ERROR(cudaMalloc((void**)&d_coveredNeighbors, g1->degrees[node] * sizeof(int)));\n","    CUDA_CHECK_ERROR(cudaMalloc((void**)&d_coveredNeighborsSize, sizeof(int)));\n","    CUDA_CHECK_ERROR(cudaMalloc((void**)&d_matrix1, g1->numVertices * g1->numVertices * sizeof(int)));\n","    CUDA_CHECK_ERROR(cudaMalloc((void**)&d_mapping1, g1->numVertices * sizeof(int)));\n","\n","    cudaStream_t stream1, stream2;\n","    cudaStreamCreate(&stream1);\n","    cudaStreamCreate(&stream2);\n","\n","    CUDA_CHECK_ERROR(cudaMemcpyAsync(d_matrix1, g1->matrix, g1->numVertices * g1->numVertices * sizeof(int), cudaMemcpyHostToDevice, stream1));\n","    CUDA_CHECK_ERROR(cudaMemcpyAsync(d_coveredNeighborsSize, &coveredNeighborsSize, sizeof(int), cudaMemcpyHostToDevice, stream1));\n","    CUDA_CHECK_ERROR(cudaMemcpyAsync(d_mapping1, state->mapping1, g1->numVertices * sizeof(int), cudaMemcpyHostToDevice, stream1));\n","\n","    int gridSize = (g1->numVertices + blockSize - 1) / blockSize;\n","\n","    findCoveredNeighborsKernel<<<gridSize, blockSize, 0, stream1>>>(d_matrix1, d_mapping1, node, d_coveredNeighbors, d_coveredNeighborsSize,\n","        g1->numVertices);\n","\n","    int g1_label = g1->nodesToLabel[node];\n","    int maxSizeCandidates = g2->labelsCardinalities[g1_label];\n","    int g1_degree = g1->degrees[node];\n","\n","    int* d_g2_vertexList, *d_g2_degrees, *d_g2_matrix, *d_g2_nodesToLabel;\n","    int* d_T2_out, *d_mapping2;\n","    int* d_candidates, *d_candidateSize, *d_commonNodes;\n","    int* candidates;\n","    int candidateSize = 0;\n","\n","    CUDA_CHECK_ERROR(cudaMalloc((void**)&d_g2_vertexList, maxSizeCandidates * sizeof(int)));\n","    CUDA_CHECK_ERROR(cudaMalloc((void**)&d_g2_degrees, g2->numVertices * sizeof(int)));\n","    CUDA_CHECK_ERROR(cudaMalloc((void**)&d_T2_out, g2->numVertices * sizeof(int)));\n","    CUDA_CHECK_ERROR(cudaMalloc((void**)&d_mapping2, g2->numVertices * sizeof(int)));\n","    CUDA_CHECK_ERROR(cudaMalloc((void**)&d_candidates, g2->numVertices * sizeof(int)));\n","    CUDA_CHECK_ERROR(cudaMalloc((void**)&d_candidateSize, sizeof(int)));\n","    CUDA_CHECK_ERROR(cudaMalloc((void**)&d_commonNodes, g2->numVertices * sizeof(int)));\n","    CUDA_CHECK_ERROR(cudaMalloc((void**)&d_g2_matrix, g2->numVertices * g2->numVertices * sizeof(int)));\n","    CUDA_CHECK_ERROR(cudaMalloc((void**)&d_g2_nodesToLabel, g2->numVertices * sizeof(int)));\n","\n","    CUDA_CHECK_ERROR(cudaMemcpyAsync(d_g2_vertexList, g2->labelToNodes[g1_label], maxSizeCandidates * sizeof(int), cudaMemcpyHostToDevice, stream2));\n","    CUDA_CHECK_ERROR(cudaMemcpyAsync(d_g2_degrees, g2->degrees, g2->numVertices * sizeof(int), cudaMemcpyHostToDevice, stream2));\n","    CUDA_CHECK_ERROR(cudaMemcpyAsync(d_T2_out, state->T2_out, g2->numVertices * sizeof(int), cudaMemcpyHostToDevice, stream2));\n","    CUDA_CHECK_ERROR(cudaMemcpyAsync(d_mapping2, state->mapping2, g2->numVertices * sizeof(int), cudaMemcpyHostToDevice, stream2));\n","    CUDA_CHECK_ERROR(cudaMemcpyAsync(d_candidateSize, &candidateSize, sizeof(int), cudaMemcpyHostToDevice, stream2));\n","    CUDA_CHECK_ERROR(cudaMemcpyAsync(d_g2_matrix, g2->matrix, g2->numVertices * g2->numVertices * sizeof(int), cudaMemcpyHostToDevice, stream2));\n","    CUDA_CHECK_ERROR(cudaMemcpyAsync(d_g2_nodesToLabel, g2->nodesToLabel, g2->numVertices * sizeof(int), cudaMemcpyHostToDevice, stream2));\n","\n","    cudaStreamSynchronize(stream1);\n","\n","    gridSize = (g2->numVertices + blockSize - 1) / blockSize;\n","    findCandidatesKernel<<<gridSize, blockSize, 0, stream2>>>(d_coveredNeighborsSize, g1_label, maxSizeCandidates, d_g2_vertexList, g1_degree,\n","        d_g2_degrees, d_T2_out, d_mapping2, d_candidates, d_candidateSize, g2->numVertices, d_commonNodes, d_coveredNeighbors,\n","        d_g2_matrix, d_mapping1, d_g2_nodesToLabel);\n","\n","    cudaStreamSynchronize(stream2);\n","\n","    candidates = (int*)malloc(maxSizeCandidates * sizeof(int));\n","    CUDA_CHECK_ERROR(cudaMemcpy(candidates, d_candidates, maxSizeCandidates * sizeof(int), cudaMemcpyDeviceToHost));\n","    CUDA_CHECK_ERROR(cudaMemcpy(&candidateSize, d_candidateSize, sizeof(int), cudaMemcpyDeviceToHost));\n","    *sizeCandidates = candidateSize;\n","\n","    cudaStreamDestroy(stream1);\n","    cudaStreamDestroy(stream2);\n","    cudaFree(d_coveredNeighbors);\n","    cudaFree(d_coveredNeighborsSize);\n","    cudaFree(d_matrix1);\n","    cudaFree(d_mapping1);\n","\n","    cudaFree(d_g2_vertexList);\n","    cudaFree(d_g2_degrees);\n","    cudaFree(d_T2_out);\n","    cudaFree(d_mapping2);\n","    cudaFree(d_candidates);\n","    cudaFree(d_candidateSize);\n","    cudaFree(d_commonNodes);\n","    cudaFree(d_g2_matrix);\n","    cudaFree(d_g2_nodesToLabel);\n","\n","    return candidates;\n","}\n","\n","\n","void vf2pp(Graph* g1, Graph* g2, State* state) {\n","    if (!checkGraphProperties(g1, g2)) {\n","        return;\n","    }\n","\n","    int* order = ordering(g1, g2);\n","\n","    //printf(\"Order:\\t\");\n","    //for(int i = 0; i < g1->numVertices; i++) {\n","    //    printf(\"%d \", order[i]);\n","    //}\n","    //printf(\"\\n\");\n","\n","    int sizeCandidates = 0;\n","    int* candidates = findCandidates(g1, g2, state, order[0], &sizeCandidates);\n","\n","    StackNode* stack = createStack();\n","    Info* info = createInfo(candidates, sizeCandidates, order[0]);\n","    push(&stack, info);\n","\n","    int matchingNode = 1;\n","    while (!isStackEmpty(stack)) {\n","        Info* info = peek(&stack);\n","        bool isMatch = false;\n","\n","        // printInfo(info);\n","\n","        for(int i = info->candidateIndex; i < info->sizeCandidates; i++) {\n","            int candidate = info->candidates[i];\n","            info->candidateIndex = i + 1;\n","\n","            int ret = cutISO(g1, g2, state, info->vertex, candidate);\n","\n","            // printf(\"CutISO: %d\\n\", ret);\n","            // printf(\"\\n\");\n","\n","            if(!ret) {\n","\n","                // printf(\"\\nMatch %d -> %d\\n\", info->vertex, candidate);\n","\n","                state->mapping1[info->vertex] = candidate;\n","                state->mapping2[candidate] = info->vertex;\n","\n","                if(isMappingFull(g1, state)) {\n","                    freeStack(stack);\n","                    free(order);\n","                    printf(\"Graphs are isomorphic\\n\");\n","                    return;\n","                }\n","\n","                updateState(g1, g2, state, info->vertex, candidate);\n","                candidates = findCandidates(g1, g2, state, order[matchingNode], &sizeCandidates);\n","                Info* info = createInfo(candidates, sizeCandidates, order[matchingNode]);\n","                push(&stack, info);\n","                matchingNode++;\n","                isMatch = true;\n","                break;\n","            }\n","        }\n","\n","        // no more candidates\n","        if(!isMatch) {\n","            Info* tmp = pop(&stack);\n","            freeInfo(tmp);\n","            matchingNode--;\n","\n","            // backtracking\n","            if(!isStackEmpty(stack)) {\n","                Info* prevInfo = peek(&stack);\n","                int candidate = state->mapping1[prevInfo->vertex];\n","                state->mapping1[prevInfo->vertex] = -1;\n","                state->mapping2[candidate] = -1;\n","                restoreState(g1, g2, state, prevInfo->vertex, candidate);\n","            }\n","        }\n","    }\n","    free(order);\n","    freeStack(stack);\n","}\n","\n","__global__ void findNeighborsKernel(int* matrix, int node, int* neighbors, int* size, int numVertices) {\n","    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n","\n","    if(idx < numVertices) {\n","        if(matrix[node * numVertices + idx] == 1) {\n","            int index = atomicAdd(size, 1);\n","            neighbors[index] = idx;\n","        }\n","    }\n","}\n","\n","__global__ void checkLabelsKernel(int* neighbors1, int* neighbors2, int* nbrSize1, int* nbrSize2, int* labelsNbr, int numVertices,\n","    int* g1_nodesToLabel, int* g2_nodesToLabel, int* d_result) {   // idx is the id of the thread in the grid\n","\n","    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n","\n","    if(idx < *nbrSize1) {\n","        int nbr1 = neighbors1[idx];\n","        int labelNbr1 = g1_nodesToLabel[nbr1];\n","        bool found = false;\n","\n","        for(int i = 0; i < *nbrSize2; i++) {\n","            int nbr2 = neighbors2[i];\n","            if(labelNbr1 == g2_nodesToLabel[nbr2]) {\n","                found = true;\n","                labelsNbr[labelNbr1] = 1;\n","                break;\n","            }\n","        }\n","\n","        if(!found) {\n","            atomicExch(d_result, 0);   // d_result is initialized to 1 by default\n","        }\n","    }\n","}\n","\n","__global__ void findNodesOfLabelKernel(int* neighbors, int* g_nodesToLabel, int label, int maxSize, int* size, int* nodes) {\n","    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n","\n","    if(idx < maxSize) {\n","        int vertex = neighbors[idx];\n","\n","        if(g_nodesToLabel[vertex] == label) {\n","            int index = atomicAdd(size, 1);   // atomicAdd returns the index respect to global memory (so can't be used shared memory)\n","            nodes[index] = vertex;\n","        }\n","    }\n","}\n","\n","__global__ void intersectionCountKernel(int* nodes, int* size, int* stateSet, int* count) {\n","    int idx = blockIdx.x * blockDim.x + threadIdx.x;    // idx is the id of the thread in the grid among all threads\n","    __shared__ int localCount;  // each block has own localCount variable (shared memory)\n","\n","    if(threadIdx.x == 0) {   // only one thread in the block initializes the localCount\n","        localCount = 0;\n","    }\n","\n","    __syncthreads();\n","\n","    if(idx < *size) {\n","        int vertex = nodes[idx];\n","\n","        if(stateSet[vertex] == 1) {\n","            atomicAdd(&localCount, 1);\n","        }\n","    }\n","\n","    __syncthreads();\n","\n","    if(threadIdx.x == 0) {  // only the thread with id 0 of each block updates the global size\n","        atomicAdd(count, localCount);\n","    }\n","}\n","\n","bool cutISO(Graph* g1, Graph* g2, State* state, int node1, int node2){\n","    // output\n","    int* d_neighbors1, *d_neighbors2;\n","    int* d_nbrSize1, *d_nbrSize2;\n","    int nbrSize1, nbrSize2;\n","\n","    // input\n","    int* d_matrix1, *d_matrix2;\n","\n","    cudaStream_t stream1, stream2, stream3;\n","    cudaStreamCreate(&stream1);\n","    cudaStreamCreate(&stream2);\n","    cudaStreamCreate(&stream3);\n","\n","    CUDA_CHECK_ERROR(cudaMalloc((void**)&d_neighbors1, g1->degrees[node1] * sizeof(int)));\n","    CUDA_CHECK_ERROR(cudaMalloc((void**)&d_nbrSize1, sizeof(int)));\n","    CUDA_CHECK_ERROR(cudaMalloc((void**)&d_matrix1, g1->numVertices * g1->numVertices * sizeof(int)));\n","\n","    CUDA_CHECK_ERROR(cudaMemsetAsync(d_nbrSize1, 0, sizeof(int), stream1));\n","    CUDA_CHECK_ERROR(cudaMemcpyAsync(d_matrix1, g1->matrix, g1->numVertices * g1->numVertices * sizeof(int), cudaMemcpyHostToDevice, stream1));\n","\n","    int gridSize = (g1->numVertices + blockSize - 1) / blockSize;\n","\n","    findNeighborsKernel<<<gridSize, blockSize, 0, stream1>>>(d_matrix1, node1, d_neighbors1, d_nbrSize1, g1->numVertices);\n","\n","    CUDA_CHECK_ERROR(cudaMalloc((void**)&d_neighbors2, g2->degrees[node2] * sizeof(int)));\n","    CUDA_CHECK_ERROR(cudaMalloc((void**)&d_nbrSize2, sizeof(int)));\n","    CUDA_CHECK_ERROR(cudaMalloc((void**)&d_matrix2, g2->numVertices * g2->numVertices * sizeof(int)));\n","\n","    CUDA_CHECK_ERROR(cudaMemsetAsync(d_nbrSize2, 0, sizeof(int), stream2));\n","    CUDA_CHECK_ERROR(cudaMemcpyAsync(d_matrix2, g2->matrix, g2->numVertices * g2->numVertices * sizeof(int), cudaMemcpyHostToDevice, stream2));\n","\n","    gridSize = (g2->numVertices + blockSize - 1) / blockSize;\n","\n","    findNeighborsKernel<<<gridSize, blockSize, 0, stream2>>>(d_matrix2, node2, d_neighbors2, d_nbrSize2, g2->numVertices);\n","\n","    // input\n","    int* d_labelsNbr, *d_g1_nodesToLabel, *d_g2_nodesToLabel;\n","    int* labelsNbr = (int*)malloc(LABELS * sizeof(int));\n","\n","    // output\n","    int* d_result;\n","    int result;\n","\n","    CUDA_CHECK_ERROR(cudaMalloc((void**)&d_labelsNbr, LABELS * sizeof(int)));\n","    CUDA_CHECK_ERROR(cudaMalloc((void**)&d_result, sizeof(int)));\n","    CUDA_CHECK_ERROR(cudaMalloc((void**)&d_g1_nodesToLabel, g1->numVertices * sizeof(int)));\n","    CUDA_CHECK_ERROR(cudaMalloc((void**)&d_g2_nodesToLabel, g2->numVertices * sizeof(int)));\n","\n","    CUDA_CHECK_ERROR(cudaMemsetAsync(d_labelsNbr, 0, LABELS * sizeof(int), stream3));\n","    CUDA_CHECK_ERROR(cudaMemsetAsync(d_result, 1, sizeof(int), stream3));\n","    CUDA_CHECK_ERROR(cudaMemcpyAsync(d_g1_nodesToLabel, g1->nodesToLabel, g1->numVertices * sizeof(int), cudaMemcpyHostToDevice, stream3));\n","    CUDA_CHECK_ERROR(cudaMemcpyAsync(d_g2_nodesToLabel, g2->nodesToLabel, g2->numVertices * sizeof(int), cudaMemcpyHostToDevice, stream3));\n","\n","    cudaStreamSynchronize(stream1);\n","    cudaStreamSynchronize(stream2);\n","\n","    CUDA_CHECK_ERROR(cudaMemcpy(&nbrSize1, d_nbrSize1, sizeof(int), cudaMemcpyDeviceToHost));\n","    CUDA_CHECK_ERROR(cudaMemcpy(&nbrSize2, d_nbrSize2, sizeof(int), cudaMemcpyDeviceToHost));\n","\n","    cudaFree(d_matrix1);\n","    cudaFree(d_matrix2);\n","\n","    gridSize = (nbrSize1 + blockSize - 1) / blockSize;\n","\n","    checkLabelsKernel<<<gridSize, blockSize, 0, stream3>>>(d_neighbors1, d_neighbors2, d_nbrSize1, d_nbrSize2,\n","        d_labelsNbr, g1->numVertices, d_g1_nodesToLabel, d_g2_nodesToLabel, d_result);\n","\n","    cudaStreamSynchronize(stream3);\n","\n","    CUDA_CHECK_ERROR(cudaMemcpy(&result, d_result, sizeof(int), cudaMemcpyDeviceToHost));\n","    CUDA_CHECK_ERROR(cudaMemcpy(labelsNbr, d_labelsNbr, LABELS * sizeof(int), cudaMemcpyDeviceToHost));\n","\n","    cudaFree(d_labelsNbr);\n","    cudaFree(d_result);\n","\n","    if(result == 0) {\n","        cudaStreamDestroy(stream1);\n","        cudaStreamDestroy(stream2);\n","        cudaStreamDestroy(stream3);\n","\n","        cudaFree(d_neighbors1);\n","        cudaFree(d_neighbors2);\n","        cudaFree(d_nbrSize1);\n","        cudaFree(d_nbrSize2);\n","        cudaFree(d_g1_nodesToLabel);\n","        cudaFree(d_g2_nodesToLabel);\n","\n","        return true;\n","    }\n","\n","    cudaStream_t stream4, stream5, stream6;\n","    cudaStreamCreate(&stream4);\n","    cudaStreamCreate(&stream5);\n","    cudaStreamCreate(&stream6);\n","\n","    // istantiating variables on device stream1 and stream2\n","    int* d_nodes_g1, *d_nodes_g2;\n","    int* d_size_g1, *d_size_g2;\n","    int size1, size2;\n","\n","    // stream 1\n","    CUDA_CHECK_ERROR(cudaMalloc((void**)&d_nodes_g1, nbrSize1 * sizeof(int)));\n","    CUDA_CHECK_ERROR(cudaMalloc((void**)&d_size_g1, sizeof(int)));\n","\n","    // stream 2\n","    CUDA_CHECK_ERROR(cudaMalloc((void**)&d_nodes_g2, nbrSize2 * sizeof(int)));\n","    CUDA_CHECK_ERROR(cudaMalloc((void**)&d_size_g2, sizeof(int)));\n","\n","    //instantiating variables on device stream3, stream4, stream5, stream6\n","    int* d_count3, *d_count4, *d_count5, *d_count6;\n","    int count3, count4, count5, count6;\n","    int* d_T1, *d_T2;\n","    int* d_T1_out, *d_T2_out;\n","\n","    // stream 3\n","    CUDA_CHECK_ERROR(cudaMalloc((void**)&d_count3, sizeof(int)));\n","    CUDA_CHECK_ERROR(cudaMalloc((void**)&d_T1, g1->numVertices * sizeof(int)));\n","    CUDA_CHECK_ERROR(cudaMemcpyAsync(d_T1, state->T1, g1->numVertices * sizeof(int), cudaMemcpyHostToDevice, stream3));\n","\n","    // stream 4\n","    CUDA_CHECK_ERROR(cudaMalloc((void**)&d_count4, sizeof(int)));\n","    CUDA_CHECK_ERROR(cudaMalloc((void**)&d_T2, g2->numVertices * sizeof(int)));\n","    CUDA_CHECK_ERROR(cudaMemcpyAsync(d_T2, state->T2, g2->numVertices * sizeof(int), cudaMemcpyHostToDevice, stream4));\n","\n","    // stream 5\n","    CUDA_CHECK_ERROR(cudaMalloc((void**)&d_count5, sizeof(int)));\n","    CUDA_CHECK_ERROR(cudaMalloc((void**)&d_T1_out, g1->numVertices * sizeof(int)));\n","    CUDA_CHECK_ERROR(cudaMemcpyAsync(d_T1_out, state->T1_out, g1->numVertices * sizeof(int), cudaMemcpyHostToDevice, stream5));\n","\n","    // stream 6\n","    CUDA_CHECK_ERROR(cudaMalloc((void**)&d_count6, sizeof(int)));\n","    CUDA_CHECK_ERROR(cudaMalloc((void**)&d_T2_out, g2->numVertices * sizeof(int)));\n","    CUDA_CHECK_ERROR(cudaMemcpyAsync(d_T2_out, state->T2_out, g2->numVertices * sizeof(int), cudaMemcpyHostToDevice, stream6));\n","\n","    bool ret = false;\n","    for(int label = 0; label < LABELS; label++) {\n","        if(labelsNbr[label] == 1) {\n","\n","            // stream 1\n","            CUDA_CHECK_ERROR(cudaMemsetAsync(d_size_g1, 0, sizeof(int), stream1));\n","\n","            gridSize = (nbrSize1 + blockSize - 1) / blockSize;\n","\n","            findNodesOfLabelKernel<<<gridSize, blockSize, 0, stream1>>>(d_neighbors1, d_g1_nodesToLabel, label, nbrSize1, d_size_g1, d_nodes_g1);\n","\n","            // stream 2\n","            CUDA_CHECK_ERROR(cudaMemsetAsync(d_size_g2, 0, sizeof(int), stream2));\n","\n","            gridSize = (nbrSize2 + blockSize - 1) / blockSize;\n","\n","            findNodesOfLabelKernel<<<gridSize, blockSize, 0, stream2>>>(d_neighbors2, d_g2_nodesToLabel, label, nbrSize2, d_size_g2, d_nodes_g2);\n","\n","            // stream 3\n","            CUDA_CHECK_ERROR(cudaMemsetAsync(d_count3, 0, sizeof(int), stream3));\n","\n","            // stream 4\n","            CUDA_CHECK_ERROR(cudaMemsetAsync(d_count4, 0, sizeof(int), stream4));\n","\n","            // stream 5\n","            CUDA_CHECK_ERROR(cudaMemsetAsync(d_count5, 0, sizeof(int), stream5));\n","\n","            // stream 6\n","            CUDA_CHECK_ERROR(cudaMemsetAsync(d_count6, 0, sizeof(int), stream6));\n","\n","            cudaStreamSynchronize(stream1);\n","            cudaStreamSynchronize(stream2);\n","\n","            CUDA_CHECK_ERROR(cudaMemcpy(&size1, d_size_g1, sizeof(int), cudaMemcpyDeviceToHost));\n","            CUDA_CHECK_ERROR(cudaMemcpy(&size2, d_size_g2, sizeof(int), cudaMemcpyDeviceToHost));\n","\n","            gridSize = (size1 + blockSize - 1) / blockSize;\n","            intersectionCountKernel<<<gridSize, blockSize, 0, stream3>>>(d_nodes_g1, d_size_g1, d_T1, d_count3);\n","\n","            gridSize = (size2 + blockSize - 1) / blockSize;\n","            intersectionCountKernel<<<gridSize, blockSize, 0, stream4>>>(d_nodes_g2, d_size_g2, d_T2, d_count4);\n","\n","            gridSize = (size1 + blockSize - 1) / blockSize;\n","            intersectionCountKernel<<<gridSize, blockSize, 0, stream5>>>(d_nodes_g1, d_size_g1, d_T1_out, d_count5);\n","\n","            gridSize = (size2 + blockSize - 1) / blockSize;\n","            intersectionCountKernel<<<gridSize, blockSize, 0, stream6>>>(d_nodes_g2, d_size_g2, d_T2_out, d_count6);\n","\n","            cudaStreamSynchronize(stream3);\n","            CUDA_CHECK_ERROR(cudaMemcpy(&count3, d_count3, sizeof(int), cudaMemcpyDeviceToHost));\n","\n","            cudaStreamSynchronize(stream4);\n","            CUDA_CHECK_ERROR(cudaMemcpy(&count4, d_count4, sizeof(int), cudaMemcpyDeviceToHost));\n","\n","            cudaStreamSynchronize(stream5);\n","            CUDA_CHECK_ERROR(cudaMemcpy(&count5, d_count5, sizeof(int), cudaMemcpyDeviceToHost));\n","\n","            cudaStreamSynchronize(stream6);\n","            CUDA_CHECK_ERROR(cudaMemcpy(&count6, d_count6, sizeof(int), cudaMemcpyDeviceToHost));\n","\n","            if(count3 != count4 || count5 != count6) {\n","                ret = true;\n","                break;\n","            }\n","        }\n","    }\n","    cudaStreamDestroy(stream1);\n","    cudaStreamDestroy(stream2);\n","    cudaStreamDestroy(stream3);\n","    cudaStreamDestroy(stream4);\n","    cudaStreamDestroy(stream5);\n","    cudaStreamDestroy(stream6);\n","\n","    cudaFree(d_neighbors1);\n","    cudaFree(d_neighbors2);\n","    cudaFree(d_nbrSize1);\n","    cudaFree(d_nbrSize2);\n","    cudaFree(d_g1_nodesToLabel);\n","    cudaFree(d_g2_nodesToLabel);\n","\n","    cudaFree(d_count3);\n","    cudaFree(d_count4);\n","    cudaFree(d_count5);\n","    cudaFree(d_count6);\n","\n","    cudaFree(d_T1);\n","    cudaFree(d_T2);\n","    cudaFree(d_T1_out);\n","    cudaFree(d_T2_out);\n","\n","    cudaFree(d_nodes_g1);\n","    cudaFree(d_size_g1);\n","    cudaFree(d_nodes_g2);\n","    cudaFree(d_size_g2);\n","\n","    return ret;\n","}\n","\n","/***** STACK FUNCTIONS *****/\n","Info* createInfo(int* candidates, int sizeCandidates, int vertex) {\n","    Info* info = (Info*)malloc(sizeof(Info));\n","    if (info == NULL) {\n","        printf(\"Error allocating memory in createInfo\\n\");\n","        exit(EXIT_FAILURE);\n","    }\n","    info->vertex = vertex;\n","    info->candidates = (int*)realloc(candidates, sizeCandidates * sizeof(int));\n","    info->sizeCandidates = sizeCandidates;\n","    info->candidateIndex = 0;\n","    return info;\n","}\n","\n","StackNode* createStackNode(Info* info) {\n","    StackNode* node = (StackNode*)malloc(sizeof(StackNode));\n","    if (node == NULL) {\n","        printf(\"Error allocating memory in createStackNode\\n\");\n","        exit(EXIT_FAILURE);\n","    }\n","    node->info = info;\n","    node->next = NULL;\n","    return node;\n","}\n","\n","void push(StackNode** top, Info* info) {\n","    StackNode* node = createStackNode(info);\n","    node->next = *top;\n","    *top = node;\n","}\n","\n","Info* pop(StackNode** top) {\n","    if (isStackEmpty(*top)) {\n","        printf(\"Stack is empty, cannot pop\\n\");\n","        return NULL;\n","    }\n","    StackNode* node = *top;\n","    Info* info = node->info;\n","    *top = node->next;\n","    free(node);\n","    return info;\n","}\n","\n","bool isStackEmpty(StackNode* top) {\n","    return top == NULL;\n","}\n","\n","void freeStack(StackNode* top) {\n","    while (!isStackEmpty(top)) {\n","        StackNode* node = top;\n","        top = top->next;\n","        freeInfo(node->info);\n","        free(node);\n","    }\n","}\n","\n","void printStack(StackNode* top) {\n","    StackNode* current = top;\n","    while (current != NULL) {\n","        printInfo(current->info);\n","        current = current->next;\n","    }\n","}\n","\n","void printInfo(Info* info) {\n","    printf(\"\\nVertex: %d\\n\", info->vertex);\n","    printf(\"Index seen: %d\\n\", info->candidateIndex);\n","    printf(\"Candidates: \");\n","    for (int i = 0; i < info->sizeCandidates; i++) {\n","        printf(\"%d \", info->candidates[i]);\n","    }\n","    printf(\"\\n\");\n","}\n","\n","void freeInfo(Info* info) {\n","    free(info->candidates);\n","    free(info);\n","}\n","\n","StackNode* createStack() {\n","    return NULL;\n","}\n","\n","Info* peek(StackNode** top) {\n","    return (*top)->info;\n","}"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
